<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> Memory usage regression
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:jemalloc-discuss%40canonware.com?Subject=Re%3A%20Memory%20usage%20regression&In-Reply-To=%3C77F42B4A75C8E94597470241D340426D02508A7534%40air.MATTER.LOCAL%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000490.html">
   <LINK REL="Next"  HREF="000492.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>Memory usage regression</H1>
    <B>Jim Kuhn</B> 
    <A HREF="mailto:jemalloc-discuss%40canonware.com?Subject=Re%3A%20Memory%20usage%20regression&In-Reply-To=%3C77F42B4A75C8E94597470241D340426D02508A7534%40air.MATTER.LOCAL%3E"
       TITLE="Memory usage regression">jkuhn at avvasi.com
       </A><BR>
    <I>Tue Oct 30 13:14:49 PDT 2012</I>
    <P><UL>
        <LI>Previous message: <A HREF="000490.html">Memory usage regression
</A></li>
        <LI>Next message: <A HREF="000492.html">Memory usage regression
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#491">[ date ]</a>
              <a href="thread.html#491">[ thread ]</a>
              <a href="subject.html#491">[ subject ]</a>
              <a href="author.html#491">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On Oct 30, 2012, at 3:49 PM, Jason Evans wrote:

&gt;<i> The preference for allocating dirty runs was a solution to excessive dirty page purging.  However, the purging policy (as of jemalloc 3.0.0) is round-robin,
</I>&gt;<i> justified only as a strategy for allowing dirty pages to accumulate in chunks before going to the considerable effort (including arena mutex operations)
</I>&gt;<i> of scanning a chunk for dirty pages.  In retrospect I'm thinking maybe this was a bad choice, and that we should go back to scanning downward through
</I>&gt;<i> memory to purge dirty pages.  The danger is that the linear scanning overhead for scanning each chunk will cause a measurable performance degradation
</I>&gt;<i> if high chunks routinely have many runs, only a few of which are unused dirty runs.  I think that problem can be solved with slightly more sophisticated
</I>&gt;<i> hysteresis though.
</I>
&gt;<i> I'll work on a diff for you to test, and see how it affects Firefox.  I'll do some testing with Facebook server loads too (quite different behavior from Firefox).
</I>&gt;<i> If this causes a major reduction in virtual memory usage for both workloads, it's probably the right thing to do, even speed-wise.
</I>
[...]

Jason (and Mike),

I've been following this closely, as I've been experiencing the exact same issue with our use of jemalloc 3.  Our application does a large number of
varied-size allocations and &quot;leaks&quot; several GB of VM each day due to the fragmentation...  When you have a diff, I can provide a third data point.

Thanks, 

Jim Kuhn

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000490.html">Memory usage regression
</A></li>
	<LI>Next message: <A HREF="000492.html">Memory usage regression
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#491">[ date ]</a>
              <a href="thread.html#491">[ thread ]</a>
              <a href="subject.html#491">[ subject ]</a>
              <a href="author.html#491">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">More information about the jemalloc-discuss
mailing list</a><br>
</body></html>
