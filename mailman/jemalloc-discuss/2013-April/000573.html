<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> Fragmentation with jemalloc
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:jemalloc-discuss%40canonware.com?Subject=Re%3A%20Fragmentation%20with%20jemalloc&In-Reply-To=%3CCAKtxisUkeZe-ninM1E3xXsCT2RWV1yNaGC3wHvFT_aReYZjzJA%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000572.html">
   <LINK REL="Next"  HREF="000574.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>Fragmentation with jemalloc</H1>
    <B>vandana shah</B> 
    <A HREF="mailto:jemalloc-discuss%40canonware.com?Subject=Re%3A%20Fragmentation%20with%20jemalloc&In-Reply-To=%3CCAKtxisUkeZe-ninM1E3xXsCT2RWV1yNaGC3wHvFT_aReYZjzJA%40mail.gmail.com%3E"
       TITLE="Fragmentation with jemalloc">shah.vandana at gmail.com
       </A><BR>
    <I>Mon Apr 22 21:25:54 PDT 2013</I>
    <P><UL>
        <LI>Previous message: <A HREF="000572.html">Fragmentation with jemalloc
</A></li>
        <LI>Next message: <A HREF="000574.html">Fragmentation with jemalloc
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#573">[ date ]</a>
              <a href="thread.html#573">[ thread ]</a>
              <a href="subject.html#573">[ subject ]</a>
              <a href="author.html#573">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Jemalloc version: 3.2.0
Operating system: Linux 2.6.32-220.7.1.el6.x86_64
Compile-time jemalloc configuration flags:
autogen            : 0
experimental       : 1
cc-silence         : 0
debug              : 0
stats              : 1
prof               : 0
prof-libunwind     : 0
prof-libgcc        : 0
prof-gcc           : 0
tcache             : 1
fill               : 1
utrace             : 0
valgrind           : 0
xmalloc            : 0
mremap             : 0
munmap             : 0
dss                : 0
lazy_lock          : 0
tls                : 1

Run-time jemalloc configuration flags:
MALLOC_CONF=narenas:1,tcache:false,lg_chunk:24

Application description:
This is a server that caches and serves data from sqlite database. The
database size can be multiple of the cache size.
The data is paged in and out as necessary to keep the process RSS under
control. The server is written in C++.
All data and metadata is dynamically allocated, so allocator is used quite
extensively.
In the test, server starts with a healthy data/RSS ratio (say 0.84). This
ratio reduces with time as RSS keeps growing
whereas server starts to page out data to keep RSS under control. In the
test the ratio came down to 0.42.

thanks,
Vandana


On Mon, Apr 22, 2013 at 11:49 PM, Jason Evans &lt;<A HREF="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">jasone at canonware.com</A>&gt; wrote:

&gt;<i> On Apr 21, 2013, at 10:01 PM, vandana shah wrote:
</I>&gt;<i> &gt; I have been trying to use jemalloc for my application and observed that
</I>&gt;<i> the rss of the process keeps on increasing.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; I ran the application with valgrind to confirm that there are no memory
</I>&gt;<i> leaks.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; To investigate more, I collected jemalloc stats after running the test
</I>&gt;<i> for few days and here is the summary for a run with narenas:1,
</I>&gt;<i> tcache:false, lg_chunk:24
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;  Arenas: 1
</I>&gt;<i> &gt;  Pointer size: 8
</I>&gt;<i> &gt;  Quantum size: 16
</I>&gt;<i> &gt;  Page size: 4096
</I>&gt;<i> &gt;  Min active:dirty page ratio per arena: 8:1
</I>&gt;<i> &gt;  Maximum thread-cached size class: 32768
</I>&gt;<i> &gt;  Chunk size: 16777216 (2^24)
</I>&gt;<i> &gt;  Allocated: 24364176040, active: 24578334720, mapped: 66739765248
</I>&gt;<i> &gt;  Current active ceiling: 24578621440
</I>&gt;<i> &gt;  chunks: nchunks   highchunks    curchunks
</I>&gt;<i> &gt;             3989         3978         3978
</I>&gt;<i> &gt;  huge: nmalloc      ndalloc    allocated
</I>&gt;<i> &gt;              3            2    117440512
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;  arenas[0]:
</I>&gt;<i> &gt;  assigned threads: 17
</I>&gt;<i> &gt;  dss allocation precedence: disabled
</I>&gt;<i> &gt;  dirty pages: 5971898:64886 active:dirty, 354265 sweeps, 18261119
</I>&gt;<i> madvises, 1180858954 purged
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; While in this state, the RSS of the process was at 54GB.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Questions:
</I>&gt;<i> &gt; 1) The difference between RSS and jemalloc active is huge (more than
</I>&gt;<i> 30GB). In my test, the difference was quite less in the beginning (say 4
</I>&gt;<i> GB) and it went on increasing with time. That seems too high to account for
</I>&gt;<i> jemalloc data structures, overhead etc. What else gets accounted in process
</I>&gt;<i> RSS - active?
</I>&gt;<i>
</I>&gt;<i> jemalloc is reporting very low page-level external fragmentation for your
</I>&gt;<i> app: 1.0 - allocated/active == 1.0 - 24364176040/24578334720 == 0.87%.
</I>&gt;<i>  However, virtual memory fragmentation is quite high: 1.0 - active/mapped
</I>&gt;<i> == 63.2%.
</I>&gt;<i>
</I>&gt;<i> &gt; 2) The allocations are fairly random, sized between 8 bytes and 2MB. Are
</I>&gt;<i> there any known issues of fragmentation for particular allocation sizes?
</I>&gt;<i>
</I>&gt;<i> If your application were to commonly allocate slightly more than one
</I>&gt;<i> chunk, then internal fragmentation would be quite high, but at little
</I>&gt;<i> actual cost to physical memory.  However, you are using 16 MiB chunks, and
</I>&gt;<i> the stats say that there's only a single huge (112-MiB) allocation.
</I>&gt;<i>
</I>&gt;<i> &gt; 3) Is there a way to tune the allocations and reduce the difference?
</I>&gt;<i>
</I>&gt;<i> I can't think of a way this could happen short of a bug in jemalloc.  Can
</I>&gt;<i> you send me a complete statistics, and provide the following?
</I>&gt;<i>
</I>&gt;<i> - jemalloc version
</I>&gt;<i> - operating system
</I>&gt;<i> - compile-time jemalloc configuration flags
</I>&gt;<i> - run-time jemalloc option flags
</I>&gt;<i> - brief description of what application does
</I>&gt;<i>
</I>&gt;<i> Hopefully that will narrow down the possible explanations.
</I>&gt;<i>
</I>&gt;<i> Thanks,
</I>&gt;<i> Jason
</I>-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20130423/c221f43c/attachment.html">http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20130423/c221f43c/attachment.html</A>&gt;
-------------- next part --------------
A non-text attachment was scrubbed...
Name: bad.log.gz
Type: application/x-gzip
Size: 8167 bytes
Desc: not available
URL: &lt;<A HREF="http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20130423/c221f43c/attachment.bin">http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20130423/c221f43c/attachment.bin</A>&gt;
</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000572.html">Fragmentation with jemalloc
</A></li>
	<LI>Next message: <A HREF="000574.html">Fragmentation with jemalloc
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#573">[ date ]</a>
              <a href="thread.html#573">[ thread ]</a>
              <a href="subject.html#573">[ subject ]</a>
              <a href="author.html#573">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">More information about the jemalloc-discuss
mailing list</a><br>
</body></html>
