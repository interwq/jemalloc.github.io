<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> Transparent Huge Pages
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:jemalloc-discuss%40canonware.com?Subject=Re%3A%20Transparent%20Huge%20Pages&In-Reply-To=%3CCAFWcpZ4ROQkvp04n93Qp4c3j1KdJZB%2BwzTBRWv27wgy%3DM%2BS54Q%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000080.html">
   <LINK REL="Next"  HREF="000082.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>Transparent Huge Pages</H1>
    <B>Justin Lebar</B> 
    <A HREF="mailto:jemalloc-discuss%40canonware.com?Subject=Re%3A%20Transparent%20Huge%20Pages&In-Reply-To=%3CCAFWcpZ4ROQkvp04n93Qp4c3j1KdJZB%2BwzTBRWv27wgy%3DM%2BS54Q%40mail.gmail.com%3E"
       TITLE="Transparent Huge Pages">justin.lebar at gmail.com
       </A><BR>
    <I>Mon Feb 20 14:08:57 PST 2012</I>
    <P><UL>
        <LI>Previous message: <A HREF="000080.html">Transparent Huge Pages
</A></li>
        <LI>Next message: <A HREF="000082.html">Transparent Huge Pages
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#81">[ date ]</a>
              <a href="thread.html#81">[ thread ]</a>
              <a href="subject.html#81">[ subject ]</a>
              <a href="author.html#81">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Okay, this behavior is not entirely ridiculous, but at least Firefox's
fork of jemalloc will need to change to work well with this.

What happens if you MADV_DONTNEED all but the first 4k after you touch
the first byte?  What about if you MADV_DONTNEED the whole thing
before you touch any part?

On Mon, Feb 20, 2012 at 7:55 PM, Jakob Blomer &lt;<A HREF="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">jakob.blomer at cern.ch</A>&gt; wrote:
&gt;<i> After thinking a bit more about it, I don't think it's a bug but this is
</I>&gt;<i> just the way transparent huge pages work. &#160;For properly aligned memory, the
</I>&gt;<i> kernel takes a 2M page. &#160;This just means 2M of real memory are gone, and I
</I>&gt;<i> think not even splitting afterwards can change that.
</I>&gt;<i>
</I>&gt;<i> The following program requires 300-400k RSS without transparent huge pages,
</I>&gt;<i> but &gt;2M with THP.
</I>&gt;<i>
</I>&gt;<i> #include &lt;unistd.h&gt;
</I>&gt;<i> #include &lt;sys/mman.h&gt;
</I>&gt;<i> #include &lt;stdio.h&gt;
</I>&gt;<i> #include &lt;errno.h&gt;
</I>&gt;<i>
</I>&gt;<i> int main() {
</I>&gt;<i> &#160;int size = 4*1024*1024;
</I>&gt;<i> &#160;int _2m = 2*1024*1024;
</I>&gt;<i> &#160;char *mapping = mmap(0x42000000, size, PROT_READ | PROT_WRITE,
</I>&gt;<i> &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; MAP_ANONYMOUS | MAP_PRIVATE, -1, 0);
</I>&gt;<i> &#160;mapping[0] = '\0';
</I>&gt;<i> &#160;printf(&quot;Region of size %d mapped at %p (error %d), aligned at 2M: %d\n&quot;,
</I>&gt;<i> size, mapping, errno, (long)mapping%_2m);
</I>&gt;<i>
</I>&gt;<i> &#160;sleep(30);
</I>&gt;<i> &#160;return 0;
</I>&gt;<i> }
</I>&gt;<i>
</I>&gt;<i> Cheers,
</I>&gt;<i> Jakob
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> On 2/20/12 5:10 PM, Justin Lebar wrote:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Hm, upon further consideration...
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> If you mmap a huge page (say, 1MB), then MADV_DONTNEED a few 4-KB
</I>&gt;&gt;<i> chunks inside, transparent huge pages should break up the huge page so
</I>&gt;&gt;<i> it can decommit the parts I asked it to decommit. &#160;If it doesn't, that
</I>&gt;&gt;<i> sounds like a kernel bug to me!
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Similarly, if I mmap 1MB, get a huge page, and then touch only a few
</I>&gt;&gt;<i> bytes in the middle, the kernel shouldn't commit a huge page.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> If huge pages is behaving how I expect, I don't see why it would cause
</I>&gt;&gt;<i> your application to use more memory.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Just to check, you're measuring RSS, not vsize, right?
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> On Mon, Feb 20, 2012 at 4:59 PM, Justin Lebar&lt;<A HREF="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">justin.lebar at gmail.com</A>&gt;
</I>&gt;&gt;<i> &#160;wrote:
</I>&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> jemalloc seems to be prone to transparent huge pages
</I>&gt;&gt;&gt;&gt;<i> (<A HREF="https://lwn.net/Articles/423584">https://lwn.net/Articles/423584</A>), presumably due to its use of mmap().
</I>&gt;&gt;&gt;&gt;<i> &#160;In
</I>&gt;&gt;&gt;&gt;<i> my case (fuse module), the initial memory consumption jumped from ~12M
</I>&gt;&gt;&gt;&gt;<i> to
</I>&gt;&gt;&gt;&gt;<i> ~27M. &#160;The use of --enable-dss helps a little, bringing the consumption
</I>&gt;&gt;&gt;&gt;<i> down
</I>&gt;&gt;&gt;&gt;<i> to ~19M.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Ouch!
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> Did anyone else experienced similar behavior? &#160;Is there an easy way of
</I>&gt;&gt;&gt;&gt;<i> avoiding transparent huge pages for jemalloc'ed memory? &#160;The only
</I>&gt;&gt;&gt;&gt;<i> workaround
</I>&gt;&gt;&gt;&gt;<i> that comes to my mind is a malloc wrapper that runs madvise(...,
</I>&gt;&gt;&gt;&gt;<i> MADV_NOHUGEPAGE) on every newly allocated chunk.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> You'd probably want to do this only on the 1MB chunks jemalloc
</I>&gt;&gt;&gt;<i> allocates for small and tiny allocations. &#160;For huge allocations (more
</I>&gt;&gt;&gt;<i> than 1MB), it's likely the user will touch the whole thing, so huge
</I>&gt;&gt;&gt;<i> pages could be a benefit.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> Cheers,
</I>&gt;&gt;&gt;&gt;<i> Jakob
</I>&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> _______________________________________________
</I>&gt;&gt;&gt;&gt;<i> jemalloc-discuss mailing list
</I>&gt;&gt;&gt;&gt;<i> <A HREF="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">jemalloc-discuss at canonware.com</A>
</I>&gt;&gt;&gt;&gt;<i> <A HREF="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">http://www.canonware.com/mailman/listinfo/jemalloc-discuss</A>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> .
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>
</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000080.html">Transparent Huge Pages
</A></li>
	<LI>Next message: <A HREF="000082.html">Transparent Huge Pages
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#81">[ date ]</a>
              <a href="thread.html#81">[ thread ]</a>
              <a href="subject.html#81">[ subject ]</a>
              <a href="author.html#81">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">More information about the jemalloc-discuss
mailing list</a><br>
</body></html>
