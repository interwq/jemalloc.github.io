<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> crash on je_arena_dalloc_bin_locked
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:jemalloc-discuss%40canonware.com?Subject=Re%3A%20crash%20on%20je_arena_dalloc_bin_locked&In-Reply-To=%3C308F62F1-1D68-4D4E-A93F-DCDEBC07308F%40canonware.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000879.html">
   <LINK REL="Next"  HREF="000877.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>crash on je_arena_dalloc_bin_locked</H1>
    <B>Jason Evans</B> 
    <A HREF="mailto:jemalloc-discuss%40canonware.com?Subject=Re%3A%20crash%20on%20je_arena_dalloc_bin_locked&In-Reply-To=%3C308F62F1-1D68-4D4E-A93F-DCDEBC07308F%40canonware.com%3E"
       TITLE="crash on je_arena_dalloc_bin_locked">jasone at canonware.com
       </A><BR>
    <I>Wed Jul  9 21:07:41 PDT 2014</I>
    <P><UL>
        <LI>Previous message: <A HREF="000879.html">crash on je_arena_dalloc_bin_locked
</A></li>
        <LI>Next message: <A HREF="000877.html">GDB Python Scripts for jemalloc(3.5)
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#880">[ date ]</a>
              <a href="thread.html#880">[ thread ]</a>
              <a href="subject.html#880">[ subject ]</a>
              <a href="author.html#880">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On Jul 9, 2014, at 6:52 PM, Eduardo Silva &lt;<A HREF="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">edsiper at gmail.com</A>&gt; wrote:
&gt;<i> On Wed, Jul 9, 2014 at 10:19 AM, Eduardo Silva &lt;<A HREF="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">edsiper at gmail.com</A>&gt; wrote:
</I>&gt;&gt;<i> On Wed, Jul 9, 2014 at 8:44 AM, Jason Evans &lt;<A HREF="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">jasone at canonware.com</A>&gt; wrote:
</I>&gt;&gt;&gt;<i> On Jul 8, 2014, at 1:28 PM, Eduardo Silva &lt;<A HREF="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">edsiper at gmail.com</A>&gt; wrote:
</I>&gt;&gt;&gt;&gt;<i> i am using jemalloc as part of our web services framework stack and
</I>&gt;&gt;&gt;&gt;<i> running on high loads (after every 6 hours of work) i find common
</I>&gt;&gt;&gt;&gt;<i> segfaults like the one described here.
</I>&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;<i> It was triggered on je_arena_dalloc_bin_locked(..). Do you have some
</I>&gt;&gt;&gt;&gt;<i> idea that what can be causing the problem ?
</I>&gt;&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;&gt;<i> (gdb) bt
</I>&gt;&gt;&gt;&gt;<i> #0  0x00007f50eab23425 in __GI_raise (sig=&lt;optimized out&gt;) at
</I>&gt;&gt;&gt;&gt;<i> ../nptl/sysdeps/unix/sysv/linux/raise.c:64
</I>&gt;&gt;&gt;&gt;<i> #1  0x00007f50eab26b8b in __GI_abort () at abort.c:91
</I>&gt;&gt;&gt;&gt;<i> #2  0x000000000040d232 in mk_signal_handler (signo=11,
</I>&gt;&gt;&gt;&gt;<i> si=0x7f50de7f96f0, context=0x7f50de7f95c0) at mk_signals.c:108
</I>&gt;&gt;&gt;&gt;<i> #3  &lt;signal handler called&gt;
</I>&gt;&gt;&gt;&gt;<i> #4  je_arena_dalloc_bin_locked (arena=0x7f50ea409240,
</I>&gt;&gt;&gt;&gt;<i> chunk=0x7f50e4c00000, ptr=&lt;optimized out&gt;, mapelm=&lt;optimized out&gt;) at
</I>&gt;&gt;&gt;&gt;<i> src/arena.c:1897
</I>&gt;&gt;&gt;<i> 
</I>&gt;&gt;&gt;<i> This looks like a crash due to a double-freed region being flushed from the thread cache.  You may be able to find the actual source of the problem if you use a debug build of jemalloc and disable thread caching (MALLOC_CONF=tcache:false).
</I>&gt;&gt;<i> 
</I>&gt;&gt;<i> thanks, working on that.
</I>&gt;<i> 
</I>&gt;<i> I saw in the program output the following:
</I>&gt;<i> 
</I>&gt;<i> &lt;jemalloc&gt;: include/jemalloc/internal/arena.h:776: Failed assertion:
</I>&gt;<i> &quot;binind == actual_binind&quot;
</I>&gt;<i> 
</I>&gt;<i> looking at the backtrace:
</I>&gt;<i> 
</I>&gt;<i> #0  0x00007fc1031aa425 in __GI_raise (sig=&lt;optimized out&gt;) at
</I>&gt;<i> ../nptl/sysdeps/unix/sysv/linux/raise.c:64
</I>&gt;<i> #1  0x00007fc1031adb8b in __GI_abort () at abort.c:91
</I>&gt;<i> #2  0x00000000004256ca in je_arena_ptr_small_binind_get
</I>&gt;<i> (ptr=&lt;optimized out&gt;, mapbits=&lt;optimized out&gt;) at
</I>&gt;<i> include/jemalloc/internal/arena.h:764
</I>&gt;<i> #3  0x00000000004259f5 in je_arena_salloc (ptr=&lt;optimized out&gt;,
</I>&gt;<i> demote=&lt;optimized out&gt;) at include/jemalloc/internal/arena.h:1015
</I>&gt;<i> #4  0x000000000041947d in je_isalloc (demote=false,
</I>&gt;<i> ptr=0x7fc0fd4173d0) at
</I>&gt;<i> include/jemalloc/internal/jemalloc_internal.h:849
</I>&gt;<i> #5  ifree (ptr=0x7fc0fd4173d0) at src/jemalloc.c:1228
</I>&gt;<i> #6  0x00007fc1025f1f6f in mk_mem_free (ptr=0x7fc0fd4173d0) at
</I>&gt;<i> ../../../src/include/mk_memory.h:98
</I>&gt;<i> 
</I>&gt;<i> it happened when releasing some memory...
</I>
A double free is still a possibility, but that particular failure mode moves buffer overflow further up on the list of possibilities.  If actual_binind seems plausible but binind does not, then somehow the chunk&#8217;s page map got corrupted, for example by double-freeing a large object.  If on the other hand binind seems plausible but actual_binind does not, then a buffer overflow may have corrupted the run header.

Jason
</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000879.html">crash on je_arena_dalloc_bin_locked
</A></li>
	<LI>Next message: <A HREF="000877.html">GDB Python Scripts for jemalloc(3.5)
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#880">[ date ]</a>
              <a href="thread.html#880">[ thread ]</a>
              <a href="subject.html#880">[ subject ]</a>
              <a href="author.html#880">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">More information about the jemalloc-discuss
mailing list</a><br>
</body></html>
