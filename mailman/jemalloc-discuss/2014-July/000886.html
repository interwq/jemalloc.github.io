<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> network registered memory and pages_purge()
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:jemalloc-discuss%40canonware.com?Subject=Re%3A%20network%20registered%20memory%20and%20pages_purge%28%29&In-Reply-To=%3CE2655E99-48B1-4C5E-9C75-8AA6BCF17159%40indiana.edu%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000885.html">
   <LINK REL="Next"  HREF="000889.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>network registered memory and pages_purge()</H1>
    <B>D'Alessandro, Luke K</B> 
    <A HREF="mailto:jemalloc-discuss%40canonware.com?Subject=Re%3A%20network%20registered%20memory%20and%20pages_purge%28%29&In-Reply-To=%3CE2655E99-48B1-4C5E-9C75-8AA6BCF17159%40indiana.edu%3E"
       TITLE="network registered memory and pages_purge()">ldalessa at indiana.edu
       </A><BR>
    <I>Thu Jul 17 11:13:37 PDT 2014</I>
    <P><UL>
        <LI>Previous message: <A HREF="000885.html">network registered memory and pages_purge()
</A></li>
        <LI>Next message: <A HREF="000889.html">network registered memory and pages_purge()
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#886">[ date ]</a>
              <a href="thread.html#886">[ thread ]</a>
              <a href="subject.html#886">[ subject ]</a>
              <a href="author.html#886">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>
On Jul 17, 2014, at 1:40 PM, Jason Evans &lt;<A HREF="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">jasone at canonware.com</A>&gt; wrote:

&gt;<i> On Jul 17, 2014, at 10:29 AM, D'Alessandro, Luke K &lt;<A HREF="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">ldalessa at indiana.edu</A>&gt; wrote:
</I>&gt;&gt;<i> We&#8217;re using jemalloc to manage network pinned memory using the custom chunk allocator/deallocator functionality. Essentially we decorate the default chunk allocator with memory registration calls. This mostly works great.
</I>&gt;&gt;<i> 
</I>&gt;&gt;<i> We just discovered though, that sometimes jemalloc will call pages_purge() on our chunks without telling us, which calls madvise().
</I>&gt;&gt;<i> 
</I>&gt;&gt;<i> [...]
</I>&gt;&gt;<i> 
</I>&gt;&gt;<i> This break our network registration, because the network card has already captured the virtual-&gt;physical mapping for the pages, and we&#8217;re not able to (nor do we want to) reregister mappings&#8212;it&#8217;s expensive and complex to keep track of.
</I>&gt;&gt;<i> 
</I>&gt;&gt;<i> We can mlock()/munlock() on some systems, but many of the systems we run on aren&#8217;t under our control and don&#8217;t like it when you mlock().
</I>&gt;&gt;<i> 
</I>&gt;&gt;<i> How important is this functionality? Can it be disabled at configure time? Would it make sense to add a dynamic configuration string to turn this off on a per-arena basis?
</I>&gt;<i> 
</I>&gt;<i> Assuming you're using jemalloc exclusively for managing the pinned memory, there's no problem at all with disabling the purging.  You can do the with MALLOC_CONF=lg_dirty_mult:-1 (or just change LG_DIRTY_MULT_DEFAULT in the source code, given that you already have other changes in place).
</I>
Thanks Jason, the environment variable works great. 

I don&#8217;t have any other changes in place, just using git master and the `arena.*.chunk.{alloc,dealloc}` functionality to register a function that forwards to the original {alloc,dalloc} and then uses IB verbs registration/deregistration on the returned chunks.

I don&#8217;t really want to to use jemalloc exclusively for managing the pinned memory&#8212;in fact, it gets used to back all of the normal malloc/free calls in the code. We use allocx() dallocx() with the pinned arena directly for network managed memory. Will the MALLOC_CONF cause us problems with the rest of the our runtime? I could link something else first, to deal with those routines if this is a bad thing to disable in general (-lc?).

&gt;<i> I'm planning to change dirty page purging quite a bit for jemalloc 4, in order to add more effective hysteresis.  The tuning mechanisms will change, but I expect it will still be possible to turn purging off completely.
</I>
Cool. It would be nice to have allocx() dallocx() take a &#8220;cache&#8221; reference instead of an arena reference, with the cache configured with arenas to handle cache misses or something to deal with multithreaded-accesses. Other than that we really like using the library and as long as our network memory doesn&#8217;t move between cores frequently, this works well.

Luke

</PRE>





<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000885.html">network registered memory and pages_purge()
</A></li>
	<LI>Next message: <A HREF="000889.html">network registered memory and pages_purge()
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#886">[ date ]</a>
              <a href="thread.html#886">[ thread ]</a>
              <a href="subject.html#886">[ subject ]</a>
              <a href="author.html#886">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://www.canonware.com/mailman/listinfo/jemalloc-discuss">More information about the jemalloc-discuss
mailing list</a><br>
</body></html>
