<tt>
&lt;div&nbsp;dir=&quot;ltr&quot;&gt;You&nbsp;don&#39;t&nbsp;want&nbsp;to&nbsp;use&nbsp;malloc&nbsp;interception&nbsp;if&nbsp;you&nbsp;care&nbsp;about&nbsp;portability/interoperability. &nbsp;For&nbsp;example,&nbsp;see&nbsp;&lt;a&nbsp;href=&quot;http://mailman.cse.ohio-state.edu/pipermail/mvapich-discuss/2014-December/005276.html&quot;&gt;http://mailman.cse.ohio-state.edu/pipermail/mvapich-discuss/2014-December/005276.html&lt;/a&gt;.&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I&nbsp;can&#39;t&nbsp;find&nbsp;the&nbsp;archives&nbsp;of &lt;a&nbsp;href=&quot;mailto:madness-developers@googlegroups.com&quot;&gt;madness-developers@googlegroups.com&lt;/a&gt;&nbsp;online&nbsp;(perhaps&nbsp;I&nbsp;am&nbsp;just&nbsp;stupid)&nbsp;but&nbsp;we&nbsp;recently&nbsp;encountered&nbsp;the&nbsp;same&nbsp;issue&nbsp;with&nbsp;JEMalloc&nbsp;and&nbsp;other&nbsp;MPI&nbsp;implementations.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I&nbsp;understand&nbsp;why&nbsp;it&nbsp;is&nbsp;tempting&nbsp;to&nbsp;intercepting&nbsp;malloc/free&nbsp;for&nbsp;MPI&nbsp;purposes,&nbsp;but&nbsp;the&nbsp;end&nbsp;result&nbsp;is&nbsp;brittle&nbsp;software&nbsp;that&nbsp;forces&nbsp;users&nbsp;to&nbsp;disable&nbsp;all&nbsp;the&nbsp;optimizations&nbsp;you&nbsp;are&nbsp;trying&nbsp;to&nbsp;enable.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;And&nbsp;it&nbsp;is&nbsp;worth&nbsp;noting&nbsp;that&nbsp;the&nbsp;abuse&nbsp;of&nbsp;malloc/free&nbsp;interception&nbsp;by&nbsp;MPI&nbsp;developers&nbsp;has&nbsp;forced&nbsp;the&nbsp;MADNESS&nbsp;team&nbsp;(or&nbsp;rather&nbsp;me)&nbsp;to&nbsp;completely&nbsp;bypass&nbsp;ISO&nbsp;C/C++&nbsp;language&nbsp;defined&nbsp;heap&nbsp;routines&nbsp;to&nbsp;prevent&nbsp;MPI&nbsp;from&nbsp;hijacking&nbsp;them&nbsp;and&nbsp;breaking&nbsp;our&nbsp;code.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Anyways,&nbsp;this&nbsp;is&nbsp;in&nbsp;no&nbsp;way&nbsp;a&nbsp;statement&nbsp;about&nbsp;JEMalloc. &nbsp;The&nbsp;results&nbsp;with&nbsp;MADNESS&nbsp;indicate&nbsp;this&nbsp;it&nbsp;is&nbsp;the&nbsp;best&nbsp;available&nbsp;allocator&nbsp;around&nbsp;(vs&nbsp;GNU,&nbsp;TCE&nbsp;and&nbsp;TBB&nbsp;mallocs),&nbsp;but&nbsp;we&nbsp;will&nbsp;have&nbsp;to&nbsp;call&nbsp;it&nbsp;explicitly&nbsp;rather&nbsp;than&nbsp;via&nbsp;symbol&nbsp;interception.&lt;/div&gt;&lt;div&gt;&lt;br&gt;Best,&lt;/div&gt;&lt;div&gt;&lt;br&gt;Jeff&lt;/div&gt;&lt;/div&gt;&lt;div&nbsp;class=&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;div&nbsp;class=&quot;gmail_quote&quot;&gt;On&nbsp;Tue,&nbsp;Oct&nbsp;20,&nbsp;2015&nbsp;at&nbsp;12:18&nbsp;PM,&nbsp;Shamis,&nbsp;Pavel&nbsp;&lt;span&nbsp;dir=&quot;ltr&quot;&gt;&lt;&lt;a&nbsp;href=&quot;mailto:shamisp@ornl.gov&quot;&nbsp;target=&quot;_blank&quot;&gt;shamisp@ornl.gov&lt;/a&gt;&gt;&lt;/span&gt;&nbsp;wrote:&lt;br&gt;&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex&quot;&gt;<br>
<br>
<br>
<br>
&lt;div&nbsp;style=&quot;word-wrap:break-word&quot;&gt;<br>
Hi&nbsp;Jeff,<br>
&lt;div&gt;&lt;br&gt;<br>
&lt;/div&gt;<br>
&lt;div&gt;Thanks&nbsp;for&nbsp;the&nbsp;link,&nbsp;seems&nbsp;like&nbsp;a&nbsp;very&nbsp;useful&nbsp;library. &lt;/div&gt;<br>
&lt;div&gt;&lt;br&gt;<br>
&lt;/div&gt;<br>
&lt;div&gt;Our&nbsp;goal&nbsp;is&nbsp;a&nbsp;bit&nbsp;different&nbsp;(and&nbsp;very&nbsp;simple/basic). &lt;/div&gt;<br>
&lt;div&gt;We&nbsp;are&nbsp;looking&nbsp;for&nbsp;a&nbsp;malloc&nbsp;library&nbsp;that&nbsp;we&nbsp;can&nbsp;use&nbsp;for&nbsp;integration&nbsp;with&nbsp;our&nbsp;registration&nbsp;cache.&lt;/div&gt;<br>
&lt;div&gt;Essentially,&nbsp;it&nbsp;redirects&nbsp;application&#39;s&nbsp;malloc()&nbsp;calls&nbsp;to&nbsp;(through&nbsp;LD_PRELOAD&nbsp;or&nbsp;rpath)&nbsp;jemalloc&nbsp;that&nbsp;is&nbsp;hooked&nbsp;up&nbsp;with&nbsp;a&nbsp;cache&nbsp;(just&nbsp;like&nbsp;in&nbsp;HPX).&lt;/div&gt;<br>
&lt;div&gt;At&nbsp;this&nbsp;stage&nbsp;we&nbsp;don&#39;t&nbsp;play&nbsp;with&nbsp;locality. &lt;/div&gt;<br>
&lt;div&gt;&lt;br&gt;<br>
&lt;/div&gt;<br>
&lt;div&gt;Thanks&nbsp;!&lt;/div&gt;<br>
&lt;div&gt;&lt;br&gt;<br>
&lt;div&gt;&lt;span&nbsp;style=&quot;border-collapse:separate;border-spacing:0px&quot;&gt;&lt;span&nbsp;style=&quot;border-collapse:separate;color:rgb(0,0,0);font-family:Helvetica;font-style:normal;font-variant:normal;font-weight:normal;letter-spacing:normal;line-height:normal;text-indent:0px;text-transform:none;white-space:normal;word-spacing:0px;font-size:medium&quot;&gt;<br>
&lt;div&nbsp;style=&quot;word-wrap:break-word&quot;&gt;<br>
&lt;span&nbsp;style=&quot;border-collapse:separate;color:rgb(0,0,0);font-family:Helvetica;font-style:normal;font-variant:normal;font-weight:normal;letter-spacing:normal;line-height:normal;text-indent:0px;text-transform:none;white-space:normal;word-spacing:0px;font-size:medium&quot;&gt;<br>
&lt;div&nbsp;style=&quot;word-wrap:break-word&quot;&gt;<br>
&lt;span&nbsp;style=&quot;border-collapse:separate;color:rgb(0,0,0);font-family:Helvetica;font-style:normal;font-variant:normal;font-weight:normal;letter-spacing:normal;line-height:normal;text-indent:0px;text-transform:none;white-space:normal;word-spacing:0px;font-size:medium&quot;&gt;<br>
&lt;div&nbsp;style=&quot;word-wrap:break-word&quot;&gt;<br>
Pavel&nbsp;(Pasha)&nbsp;Shamis&lt;/div&gt;<br>
&lt;div&nbsp;style=&quot;word-wrap:break-word&quot;&gt;<br>
---&lt;br&gt;<br>
Computer&nbsp;Science&nbsp;Research&nbsp;Group&lt;br&gt;<br>
Computer&nbsp;Science&nbsp;and&nbsp;Math&nbsp;Division&lt;br&gt;<br>
Oak&nbsp;Ridge&nbsp;National&nbsp;Laboratory&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;/div&gt;<br>
&lt;/span&gt;&lt;/div&gt;<br>
&lt;/span&gt;&lt;/div&gt;<br>
&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;div&nbsp;class=&quot;h5&quot;&gt;<br>
&lt;br&gt;<br>
&lt;div&gt;<br>
&lt;div&gt;On&nbsp;Oct&nbsp;20,&nbsp;2015,&nbsp;at&nbsp;11:31&nbsp;AM,&nbsp;Jeff&nbsp;Hammond&nbsp;&lt;&lt;a&nbsp;href=&quot;mailto:jeff.science@gmail.com&quot;&nbsp;target=&quot;_blank&quot;&gt;jeff.science@gmail.com&lt;/a&gt;&gt;&nbsp;wrote:&lt;/div&gt;<br>
&lt;br&gt;<br>
&lt;blockquote&nbsp;type=&quot;cite&quot;&gt;<br>
&lt;div&nbsp;dir=&quot;ltr&quot;&gt;Hi&nbsp;Pavel,<br>
&lt;div&gt;&lt;br&gt;<br>
&lt;/div&gt;<br>
&lt;div&gt;You&nbsp;may&nbsp;find &lt;a&nbsp;href=&quot;http://memkind.github.io/memkind/&quot;&nbsp;target=&quot;_blank&quot;&gt;http://memkind.github.io/memkind/&lt;/a&gt;&nbsp;relevant. &nbsp;In&nbsp;particular, &lt;a&nbsp;href=&quot;http://memkind.github.io/memkind/memkind_arch_20150318.pdf&quot;&nbsp;target=&quot;_blank&quot;&gt;http://memkind.github.io/memkind/memkind_arch_20150318.pdf&lt;/a&gt;<br>
&nbsp;section&nbsp;2.2&nbsp;and&nbsp;2.3&nbsp;discusses&nbsp;exactly&nbsp;the&nbsp;issues&nbsp;you&nbsp;raise. &nbsp;We&nbsp;also&nbsp;note&nbsp;that&nbsp;memkind&nbsp;is&nbsp;intended&nbsp;to&nbsp;support&nbsp;multiple&nbsp;types&nbsp;of&nbsp;memory&nbsp;within&nbsp;a&nbsp;node,&nbsp;such&nbsp;as&nbsp;one&nbsp;might&nbsp;encounter&nbsp;in&nbsp;a&nbsp;platform&nbsp;such&nbsp;as&nbsp;Knights&nbsp;Landing. &nbsp;You&nbsp;are&nbsp;free&nbsp;to&nbsp;imagine&nbsp;how&nbsp;it&nbsp;might&nbsp;map<br>
&nbsp;to&nbsp;OpenPOWER&nbsp;based&nbsp;upon&nbsp;your&nbsp;superior&nbsp;knowledge&nbsp;of&nbsp;that&nbsp;platform&nbsp;:-)&lt;/div&gt;<br>
&lt;div&gt;&lt;br&gt;<br>
&lt;/div&gt;<br>
&lt;div&gt;While&nbsp;I&nbsp;recognize&nbsp;that&nbsp;the&nbsp;origins&nbsp;of&nbsp;memkind&nbsp;at&nbsp;Intel&nbsp;may&nbsp;pose&nbsp;a&nbsp;challenge&nbsp;for&nbsp;some&nbsp;in&nbsp;the&nbsp;OpenPOWER&nbsp;family,&nbsp;it&nbsp;would&nbsp;be&nbsp;tremendously&nbsp;valuable&nbsp;to&nbsp;the&nbsp;community&nbsp;if&nbsp;it&nbsp;was&nbsp;reused&nbsp;for&nbsp;MPI&nbsp;and&nbsp;OpenSHMEM&nbsp;projects,&nbsp;rather&nbsp;than&nbsp;the&nbsp;UCX&nbsp;team&nbsp;trying&nbsp;to&nbsp;implement<br>
&nbsp;something&nbsp;new. &nbsp;As&nbsp;you&nbsp;know,&nbsp;the&nbsp;both&nbsp;MPI&nbsp;and&nbsp;OpenSHMEM&nbsp;should&nbsp;run&nbsp;on&nbsp;a&nbsp;range&nbsp;of&nbsp;platforms,&nbsp;and&nbsp;it&nbsp;doubles&nbsp;the&nbsp;implementation&nbsp;effort&nbsp;in&nbsp;all&nbsp;relevant&nbsp;projects&nbsp;(MPICH,&nbsp;OpenMPI,&nbsp;OpenSHMEM&nbsp;reference,&nbsp;etc.)&nbsp;if&nbsp;UCX&nbsp;goes&nbsp;in&nbsp;a&nbsp;different&nbsp;direction.&lt;/div&gt;<br>
&lt;div&gt;&lt;br&gt;<br>
&lt;/div&gt;<br>
&lt;div&gt;I&nbsp;would&nbsp;be&nbsp;happy&nbsp;to&nbsp;introduce&nbsp;you&nbsp;to&nbsp;the&nbsp;memkind&nbsp;developers&nbsp;(I&nbsp;am&nbsp;not&nbsp;one&nbsp;of&nbsp;them,&nbsp;just&nbsp;someone&nbsp;who&nbsp;helps&nbsp;them&nbsp;understand&nbsp;user/client&nbsp;requirements).&lt;/div&gt;<br>
&lt;div&gt;&lt;br&gt;<br>
&lt;/div&gt;<br>
&lt;div&gt;Best,&lt;/div&gt;<br>
&lt;div&gt;&lt;br&gt;<br>
&lt;/div&gt;<br>
&lt;div&gt;Jeff&lt;/div&gt;<br>
&lt;div&gt;&lt;br&gt;<br>
&lt;/div&gt;<br>
&lt;/div&gt;<br>
&lt;div&nbsp;class=&quot;gmail_extra&quot;&gt;&lt;br&gt;<br>
&lt;div&nbsp;class=&quot;gmail_quote&quot;&gt;On&nbsp;Thu,&nbsp;Oct&nbsp;15,&nbsp;2015&nbsp;at&nbsp;8:45&nbsp;AM,&nbsp;Shamis,&nbsp;Pavel&nbsp;&lt;span&nbsp;dir=&quot;ltr&quot;&gt;<br>
&lt;&lt;a&nbsp;href=&quot;mailto:shamisp@ornl.gov&quot;&nbsp;target=&quot;_blank&quot;&gt;shamisp@ornl.gov&lt;/a&gt;&gt;&lt;/span&gt;&nbsp;wrote:&lt;br&gt;<br>
&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex&quot;&gt;<br>
Dear&nbsp;Jemalloc&nbsp;Community,&lt;br&gt;<br>
&lt;br&gt;<br>
We&nbsp;are&nbsp;developer&nbsp;of&nbsp;UCX&nbsp;project&nbsp;[1]&nbsp;and&nbsp;as&nbsp;part&nbsp;of&nbsp;the&nbsp;effort&lt;br&gt;<br>
we&nbsp;are&nbsp;looking&nbsp;for&nbsp;a&nbsp;malloc&nbsp;library&nbsp;that&nbsp;supports&nbsp;hooks&nbsp;for&nbsp;alloc/dealloc&nbsp;chunks&nbsp;and&nbsp;can&nbsp;be&nbsp;used&nbsp;for&nbsp;the&nbsp;following:&lt;br&gt;<br>
&lt;br&gt;<br>
(a)&nbsp;Allocation&nbsp;of&nbsp;memory&nbsp;that&nbsp;can&nbsp;be&nbsp;shared&nbsp;transparently&nbsp;between&nbsp;processes&nbsp;on&nbsp;the&nbsp;same&nbsp;node.&nbsp;For&nbsp;this&nbsp;purpose&nbsp;we&nbsp;would&nbsp;like&nbsp;to&nbsp;mmap&nbsp;memory&nbsp;with&nbsp;MAP_SHARED.&nbsp;This&nbsp;is&nbsp;very&nbsp;useful&nbsp;for&nbsp;implementation&nbsp;for&nbsp;Remote&nbsp;Memory&nbsp;Access&nbsp;(RMA)&nbsp;operations&nbsp;in&nbsp;MPI-3&nbsp;one-sided<br>
&nbsp;[2]&nbsp;and&nbsp;OpenSHMEM&nbsp;[3]&nbsp;communication&nbsp;libraries.&nbsp;This&nbsp;allow&nbsp;a&nbsp;remote&nbsp;process&nbsp;to&nbsp;map&nbsp;user&nbsp;allocated&nbsp;memory&nbsp;and&nbsp;provide&nbsp;RMA&nbsp;operations&nbsp;through&nbsp;memcpy().&lt;br&gt;<br>
&lt;br&gt;<br>
(b)&nbsp;Implementation&nbsp;of&nbsp;memory&nbsp;de-allocation&nbsp;hooks&nbsp;for&nbsp;RDMA&nbsp;hardware&nbsp;(Infiniband,&nbsp;ROCE,&nbsp;iWarp&nbsp;etc.).&nbsp;For&nbsp;optimization&nbsp;purpose&nbsp;we&nbsp;implement&nbsp;a&nbsp;lazy&nbsp;memory&nbsp;de-registration&nbsp;(memory&nbsp;unpinning)&nbsp;policy&nbsp;and&nbsp;we&nbsp;use&nbsp;the&nbsp;hook&nbsp;for&nbsp;the &nbsp;notification&nbsp;of&nbsp;communication&nbsp;library<br>
&nbsp;about&nbsp;memory&nbsp;release&nbsp;event.&nbsp;On&nbsp;the&nbsp;event,&nbsp;we&nbsp;cleanup&nbsp;our&nbsp;registration&nbsp;cache&nbsp;and&nbsp;de-register&nbsp;(unpin)&nbsp;the&nbsp;memory&nbsp;on&nbsp;hardware.&lt;br&gt;<br>
&lt;br&gt;<br>
Based&nbsp;on&nbsp;this&nbsp;requirements&nbsp;we&nbsp;would&nbsp;like&nbsp;to&nbsp;understand&nbsp;what&nbsp;is&nbsp;the&nbsp;best&nbsp;approach&nbsp;for&nbsp;integration&nbsp;this&nbsp;functionality&nbsp;within&nbsp;jemalloc.&lt;br&gt;<br>
&lt;br&gt;<br>
Regards,&lt;br&gt;<br>
Pasha&nbsp;&amp;&nbsp;Yossi&lt;br&gt;<br>
&lt;br&gt;<br>
[1]&nbsp;OpenUCX:&nbsp;&lt;a&nbsp;href=&quot;https://github.com/openucx/ucx&quot;&nbsp;rel=&quot;noreferrer&quot;&nbsp;target=&quot;_blank&quot;&gt;<br>
https://github.com/openucx/ucx&lt;/a&gt;&nbsp;or&nbsp;&lt;a&nbsp;href=&quot;http://www.openucx.org/&quot;&nbsp;rel=&quot;noreferrer&quot;&nbsp;target=&quot;_blank&quot;&gt;<br>
www.openucx.org&lt;/a&gt;&lt;br&gt;<br>
[2]&nbsp;MPI&nbsp;SPEC:&nbsp;&lt;a&nbsp;href=&quot;http://www.mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf&quot;&nbsp;rel=&quot;noreferrer&quot;&nbsp;target=&quot;_blank&quot;&gt;<br>
http://www.mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf&lt;/a&gt;&lt;br&gt;<br>
[3]&nbsp;OpenSHMEM&nbsp;SPEC:&nbsp;&lt;a&nbsp;href=&quot;http://bongo.cs.uh.edu/site/sites/default/site_files/openshmem-specification-1.2.pdf&quot;&nbsp;rel=&quot;noreferrer&quot;&nbsp;target=&quot;_blank&quot;&gt;<br>
http://bongo.cs.uh.edu/site/sites/default/site_files/openshmem-specification-1.2.pdf&lt;/a&gt;&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
_______________________________________________&lt;br&gt;<br>
jemalloc-discuss&nbsp;mailing&nbsp;list&lt;br&gt;<br>
&lt;a&nbsp;href=&quot;mailto:jemalloc-discuss@canonware.com&quot;&nbsp;target=&quot;_blank&quot;&gt;jemalloc-discuss@canonware.com&lt;/a&gt;&lt;br&gt;<br>
&lt;a&nbsp;href=&quot;http://www.canonware.com/mailman/listinfo/jemalloc-discuss&quot;&nbsp;rel=&quot;noreferrer&quot;&nbsp;target=&quot;_blank&quot;&gt;http://www.canonware.com/mailman/listinfo/jemalloc-discuss&lt;/a&gt;&lt;br&gt;<br>
&lt;/blockquote&gt;<br>
&lt;/div&gt;<br>
&lt;br&gt;<br>
&lt;br&nbsp;clear=&quot;all&quot;&gt;<br>
&lt;div&gt;&lt;br&gt;<br>
&lt;/div&gt;<br>
--&nbsp;&lt;br&gt;<br>
&lt;div&gt;Jeff&nbsp;Hammond&lt;br&gt;<br>
&lt;a&nbsp;href=&quot;mailto:jeff.science@gmail.com&quot;&nbsp;target=&quot;_blank&quot;&gt;jeff.science@gmail.com&lt;/a&gt;&lt;br&gt;<br>
&lt;a&nbsp;href=&quot;http://jeffhammond.github.io/&quot;&nbsp;target=&quot;_blank&quot;&gt;http://jeffhammond.github.io/&lt;/a&gt;&lt;/div&gt;<br>
&lt;/div&gt;<br>
&lt;/blockquote&gt;<br>
&lt;/div&gt;<br>
&lt;br&gt;<br>
&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;<br>
&lt;/div&gt;<br>
<br>
&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;br&nbsp;clear=&quot;all&quot;&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;--&nbsp;&lt;br&gt;&lt;div&nbsp;class=&quot;gmail_signature&quot;&gt;Jeff&nbsp;Hammond&lt;br&gt;&lt;a&nbsp;href=&quot;mailto:jeff.science@gmail.com&quot;&nbsp;target=&quot;_blank&quot;&gt;jeff.science@gmail.com&lt;/a&gt;&lt;br&gt;&lt;a&nbsp;href=&quot;http://jeffhammond.github.io/&quot;&nbsp;target=&quot;_blank&quot;&gt;http://jeffhammond.github.io/&lt;/a&gt;&lt;/div&gt;<br>
&lt;/div&gt;<br>

</tt>
