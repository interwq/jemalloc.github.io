<tt>
&lt;div&nbsp;dir=&quot;ltr&quot;&gt;Perhaps&nbsp;I&nbsp;am&nbsp;tone&nbsp;deaf.&nbsp;&quot;extremely&nbsp;expensive&quot;&nbsp;sounds,&nbsp;to&nbsp;my&nbsp;ear,&nbsp;worse&nbsp;than&nbsp;the&nbsp;reality&nbsp;that&nbsp;I&#39;ve&nbsp;experienced. &nbsp;But&nbsp;one&nbsp;persons&nbsp;&quot;extreme&quot;&nbsp;might&nbsp;be&nbsp;another&#39;s&nbsp;&quot;moderate&quot;. &nbsp;Rather&nbsp;than&nbsp;use&nbsp;that&nbsp;kind&nbsp;of&nbsp;subjective&nbsp;adjective,&nbsp;I&#39;ve&nbsp;tried&nbsp;to&nbsp;give&nbsp;numbers,&nbsp;and&nbsp;it&nbsp;sounds&nbsp;like&nbsp;we&nbsp;are&nbsp;basically&nbsp;in&nbsp;agreement&nbsp;about&nbsp;the&nbsp;costs.&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;To&nbsp;me,&nbsp;what&nbsp;is&nbsp;interesting&nbsp;about&nbsp;these&nbsp;numbers&nbsp;is&nbsp;that&nbsp;to&nbsp;overcome&nbsp;the&nbsp;lock&nbsp;overhead,&nbsp;a&nbsp;thread&nbsp;cache&nbsp;can&nbsp;be&nbsp;small.&nbsp; (There&nbsp;I&nbsp;go&nbsp;with&nbsp;a&nbsp;subjective&nbsp;adjective&nbsp;again...)&nbsp; For&nbsp;example,&nbsp;if&nbsp;the&nbsp;locked&nbsp;version&nbsp;is&nbsp;5x&nbsp;as&nbsp;expensive&nbsp;as&nbsp;the&nbsp;unlocked,&nbsp;then&nbsp;a&nbsp;thread&nbsp;cache&nbsp;that&nbsp;holds&nbsp;5&nbsp;objects&nbsp;will&nbsp;reduce&nbsp;the&nbsp;effective&nbsp;cost&nbsp;to&nbsp;2x&nbsp;the&nbsp;unlocked&nbsp;cache,&nbsp;in&nbsp;the&nbsp;worst&nbsp;case. &nbsp;A&nbsp;thread&nbsp;cache&nbsp;that&nbsp;holds&nbsp;20&nbsp;objects&nbsp;reduces&nbsp;the&nbsp;worst-case&nbsp;overhead&nbsp;to&nbsp;25%. &nbsp;In&nbsp;some&nbsp;allocators,&nbsp;the&nbsp;thread&nbsp;cache&nbsp;is&nbsp;much&nbsp;larger&nbsp;(perhaps&nbsp;thousands&nbsp;of&nbsp;objects)&nbsp;because&nbsp;it&nbsp;is&nbsp;trying&nbsp;to&nbsp;overcome&nbsp;the&nbsp;200ns&nbsp;contended-lock&nbsp;overhead&nbsp;instead&nbsp;of&nbsp;the&nbsp;5ns&nbsp;uncontended-lock&nbsp;overhead. &nbsp;On&nbsp;modern&nbsp;x86&nbsp;processors,&nbsp;it&nbsp;isn&#39;t&nbsp;always&nbsp;necessary&nbsp;to&nbsp;take&nbsp;heroic&nbsp;measures&nbsp;to&nbsp;avoid&nbsp;locks&nbsp;99.9%&nbsp;of&nbsp;the&nbsp;time. &nbsp;It&#39;s&nbsp;sometimes&nbsp;good&nbsp;enough&nbsp;to&nbsp;avoid&nbsp;locks&nbsp;in&nbsp;something&nbsp;like&nbsp;80%&nbsp;of&nbsp;the&nbsp;cases.&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;One&nbsp;way&nbsp;to&nbsp;make&nbsp;such&nbsp;a&nbsp;thread&nbsp;cache&nbsp;work&nbsp;is&nbsp;to&nbsp;maintain&nbsp;a&nbsp;doubly-linked&nbsp;list&nbsp;so&nbsp;that&nbsp;when&nbsp;the&nbsp;lock&nbsp;*is*&nbsp;acquired&nbsp;(e.g.,&nbsp;when&nbsp;the&nbsp;thread&nbsp;cache&nbsp;fills&nbsp;up&nbsp;on&nbsp;a&nbsp;free()),&nbsp;all&nbsp;5&nbsp;objects&nbsp;in&nbsp;the&nbsp;thread&nbsp;cache&nbsp;can&nbsp;be&nbsp;moved&nbsp;to&nbsp;the&nbsp;per-core&nbsp;cache&nbsp;with&nbsp;a&nbsp;constant&nbsp;number&nbsp;of&nbsp;memory&nbsp;references. &nbsp;One&nbsp;also&nbsp;needs&nbsp;a&nbsp;little&nbsp;hysteresis:&nbsp;so&nbsp;one&nbsp;might&nbsp;use&nbsp;two&nbsp;doubly-linked&nbsp;lists&nbsp;in&nbsp;the&nbsp;per-thread&nbsp;cache,&nbsp;and&nbsp;an&nbsp;array&nbsp;of&nbsp;doubly-linked&nbsp;lists&nbsp;(each&nbsp;containing&nbsp;5&nbsp;objects)&nbsp;in&nbsp;the&nbsp;per-core&nbsp;cache. &nbsp;When&nbsp;calling&nbsp;free(),&nbsp;if&nbsp;both&nbsp;doubly-linked&nbsp;lists&nbsp;are&nbsp;full,&nbsp;then&nbsp;move&nbsp;one&nbsp;of&nbsp;them&nbsp;to&nbsp;the&nbsp;per-core&nbsp;cache. &nbsp;When&nbsp;calling&nbsp;malloc(),&nbsp;if&nbsp;both&nbsp;doubly-linked&nbsp;lists&nbsp;are&nbsp;empty,&nbsp;then&nbsp;get&nbsp;a&nbsp;collection&nbsp;of&nbsp;5&nbsp;objects&nbsp;from&nbsp;the&nbsp;per-core&nbsp;cache. &nbsp;Similarly,&nbsp;when&nbsp;the&nbsp;per-core&nbsp;cache&nbsp;gets&nbsp;too&nbsp;full,&nbsp;a&nbsp;group&nbsp;of&nbsp;5&nbsp;objects&nbsp;can&nbsp;be&nbsp;moved&nbsp;from&nbsp;a&nbsp;per-core&nbsp;cache&nbsp;to&nbsp;a&nbsp;global&nbsp;cache&nbsp;using&nbsp;only&nbsp;O(1)&nbsp;operations,&nbsp;and&nbsp;with&nbsp;a&nbsp;little&nbsp;hysteresis,&nbsp;that&nbsp;operation&nbsp;will&nbsp;seldom&nbsp;occur.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;I&#39;m&nbsp;curious. &nbsp;How&nbsp;big&nbsp;is&nbsp;the&nbsp;thread&nbsp;cache&nbsp;in&nbsp;jemalloc?&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;-Bradley&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&nbsp;class=&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;div&nbsp;class=&quot;gmail_quote&quot;&gt;On&nbsp;Tue,&nbsp;Feb&nbsp;10,&nbsp;2015&nbsp;at&nbsp;1:11&nbsp;AM,&nbsp;Daniel&nbsp;Micay&nbsp;&lt;span&nbsp;dir=&quot;ltr&quot;&gt;&lt;&lt;a&nbsp;href=&quot;mailto:danielmicay@gmail.com&quot;&nbsp;target=&quot;_blank&quot;&gt;danielmicay@gmail.com&lt;/a&gt;&gt;&lt;/span&gt;&nbsp;wrote:&lt;br&gt;&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex&quot;&gt;&lt;span&nbsp;class=&quot;&quot;&gt;On&nbsp;10/02/15&nbsp;12:53&nbsp;AM,&nbsp;Bradley&nbsp;C.&nbsp;Kuszmaul&nbsp;wrote:&lt;br&gt;<br>
&gt;&nbsp;Lock&nbsp;instructions&nbsp;on&nbsp;modern&nbsp;x86&nbsp;processors&nbsp;aren&#39;t&nbsp;really&nbsp;that&lt;br&gt;<br>
&gt;&nbsp;expensive. &nbsp;What&nbsp;is&nbsp;expensive&nbsp;is&nbsp;lock&nbsp;contention. &nbsp;When&nbsp;I&#39;ve&nbsp;measured&lt;br&gt;<br>
&gt;&nbsp;something&nbsp;code&nbsp;that&nbsp;does&nbsp;this&nbsp;in&nbsp;a&nbsp;bunch&nbsp;of&nbsp;concurrent&nbsp;threads:&lt;br&gt;<br>
&gt; &nbsp; 1.&nbsp;acquire_lock()&lt;br&gt;<br>
&gt; &nbsp; 2.&nbsp;do_something_really_small_on_thread_local_data()&lt;br&gt;<br>
&gt; &nbsp; 3.&nbsp;release_lock()&lt;br&gt;<br>
&gt;&lt;br&gt;<br>
&gt;&nbsp;It&nbsp;costs&nbsp;about&nbsp;1ns&nbsp;to&nbsp;do&nbsp;step&nbsp;2&nbsp;with&nbsp;no&nbsp;locks.&lt;br&gt;<br>
&gt;&nbsp;It&nbsp;costs&nbsp;about&nbsp;5ns&nbsp;to&nbsp;acquire&nbsp;the&nbsp;lock&nbsp;if&nbsp;the&nbsp;lock&nbsp;is&nbsp;thread-local,&nbsp;and&lt;br&gt;<br>
&gt;&nbsp;thus&nbsp;not&nbsp;actually&nbsp;contended.&lt;br&gt;<br>
&gt;&nbsp;It&nbsp;costs&nbsp;about&nbsp;100ns-200ns&nbsp;if&nbsp;the&nbsp;lock&nbsp;is&nbsp;actually&nbsp;contended.&lt;br&gt;<br>
&gt;&lt;br&gt;<br>
&gt;&nbsp;I&#39;ve&nbsp;found&nbsp;that&nbsp;these&nbsp;measurements&nbsp;have&nbsp;changed&nbsp;the&nbsp;way&nbsp;I&nbsp;write&lt;br&gt;<br>
&gt;&nbsp;lock-based&nbsp;code. &nbsp;For&nbsp;example,&nbsp;I&nbsp;like&nbsp;per-core&nbsp;data&nbsp;structures&nbsp;that&nbsp;need&lt;br&gt;<br>
&gt;&nbsp;a&nbsp;lock,&nbsp;because&nbsp;the&nbsp;per-core&nbsp;lock&nbsp;is&nbsp;almost&nbsp;always&nbsp;uncontended. &nbsp;(The&lt;br&gt;<br>
&gt;&nbsp;difference&nbsp;between&nbsp;per-core&nbsp;and&nbsp;per-thread&nbsp;shows&nbsp;up&nbsp;only&nbsp;when&nbsp;a&nbsp;thread&lt;br&gt;<br>
&gt;&nbsp;is&nbsp;preempted.)&lt;br&gt;<br>
&gt;&lt;br&gt;<br>
&gt;&nbsp;-Badley&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;/span&gt;A&nbsp;lock&nbsp;prefix&nbsp;*is*&nbsp;very&nbsp;expensive&nbsp;in&nbsp;this&nbsp;context.&nbsp;The&nbsp;cost&nbsp;of&nbsp;locking&lt;br&gt;<br>
and&nbsp;unlocking&nbsp;is&nbsp;where&nbsp;up&nbsp;to&nbsp;50%&nbsp;of&nbsp;the&nbsp;time&nbsp;is&nbsp;spent&nbsp;in&nbsp;a&nbsp;fast&nbsp;memory&lt;br&gt;<br>
allocator&nbsp;without&nbsp;thread&nbsp;caching,&nbsp;*without*&nbsp;contention.&nbsp;It&#39;s&nbsp;why&nbsp;thread&lt;br&gt;<br>
caching&nbsp;results&nbsp;in&nbsp;a&nbsp;huge&nbsp;performance&nbsp;win&nbsp;even&nbsp;when&nbsp;it&#39;s&nbsp;only&nbsp;being&lt;br&gt;<br>
filled&nbsp;and&nbsp;flushed&nbsp;with&nbsp;no&nbsp;reuse.&nbsp;For&nbsp;example,&nbsp;making&nbsp;an&nbsp;intrusive&nbsp;list&lt;br&gt;<br>
with&nbsp;one&nbsp;million&nbsp;nodes&nbsp;and&nbsp;then&nbsp;freeing&nbsp;the&nbsp;entire&nbsp;thing&nbsp;is&nbsp;~2x&nbsp;faster&lt;br&gt;<br>
with&nbsp;a&nbsp;thread&nbsp;cache&nbsp;on&nbsp;top&nbsp;(with&nbsp;a&nbsp;fast&nbsp;O(1)&nbsp;slab&nbsp;allocator&nbsp;at&nbsp;least).&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;<br>

</tt>
