From jasone at canonware.com  Mon Aug 17 15:16:31 2015
From: jasone at canonware.com (Jason Evans)
Date: Mon, 17 Aug 2015 15:16:31 -0700
Subject: Jemalloc 4.0
In-Reply-To: <CAGvmEXj3227VYwecakSHzON_MOREgjN0F+Exh3Q=KD_eYkyvQw@mail.gmail.com>
References: <CAGvmEXj3227VYwecakSHzON_MOREgjN0F+Exh3Q=KD_eYkyvQw@mail.gmail.com>
Message-ID: <539BCA29-3E21-4DDB-8FCD-D017A86F5541@canonware.com>

On Jul 1, 2015, at 3:57 AM, SNL <snl20465 at gmail.com> wrote:
> I am using some of the features present in Dev branch and so far things are looking stable, would be good to know if a 4.0 is in the offing. As I see, it is nearing but is there a deadline or release by date ? 

jemalloc 4.0.0 was release today.

Apologies for the late reply; the mailing lists haven't been delivering mail for roughly two months!

Thanks,
Jason

From jasone at canonware.com  Mon Aug 17 15:20:43 2015
From: jasone at canonware.com (Jason Evans)
Date: Mon, 17 Aug 2015 15:20:43 -0700
Subject: arena cache being reused
In-Reply-To: <CANtHk4k+u-S8aKF7pvc4o3bS+EQV5djmhKGMhxpSVSze6oRw7g@mail.gmail.com>
References: <CANtHk4k+u-S8aKF7pvc4o3bS+EQV5djmhKGMhxpSVSze6oRw7g@mail.gmail.com>
Message-ID: <441203B4-064C-4C72-BAF2-FB19FE675CB1@canonware.com>

On Jul 8, 2015, at 3:42 PM, Christopher Ferris <cferris at google.com> wrote:
> Using the current version of the dev jemalloc, I found a case where jemalloc reuses a previously freed pointer. Specifically, the arena cache pointer can get freed, but reused.
> 
> This can happen when a thread is ending and the key destroy functions are being called. If the jemalloc key destroy function is called, the arena cache is destroyed. But if another key destroy function is called which allocates memory, the old arena cache pointer can be reused, and have the arena pointers written to it.
> 
> I think the fix is to change the arenas_cache_cleanup function to:
> 
> void
> arenas_cache_cleanup(tsd_t *tsd)
> {
>         arena_t **arenas_cache;
> 
>         arenas_cache = tsd_arenas_cache_get(tsd);
>         if (arenas_cache != NULL) {
>                 bool *arenas_cache_bypassp = tsd_arenas_cache_bypassp_get(tsd);
>                 *arenas_cache_bypassp = true;
>                 tsd_arenas_cache_set(tsd, NULL);
>                 a0dalloc(arenas_cache);
>         }
> }
> 
> I believe the bypass has to be set so that another arena cache is not allocated since that memory would be leaked since there is not going to be another call to the arenas_cache_cleanup function. I think this is the only possible way something could be reused when an allocation is made after the jemalloc key destroy function is called, but I might have missed something.
> 
> This might be particular to the fact that my config uses pthread_key_create for the tsd data, but it might apply to other configs.
> 
> Does this solution seem reasonable?

Unfortunately I didn't see this email until after the 4.0.0 release, because the mailing lists haven't been delivering email for the past two months (ouch).  Does this problem still exist with 4.0.0?

Thanks,
Jason

From marko at kevac.org  Mon Aug  3 16:02:10 2015
From: marko at kevac.org (marko at kevac.org)
Date: Mon, 03 Aug 2015 23:02:10 +0000
Subject: assertion pageind >= map_bias
Message-ID: <CA+RAKy7tTFWYg7JNpN4Q9oHZZ=3d6_2e+JhUHzWqafGQfpnpZA@mail.gmail.com>

Hi.

We are using jemalloc in our internal project and we have been experiencing
very strange memory corruptions lately, so we decided to build jemalloc
with --enable-debug and --enable-fill and give it a try.

Also, we used this env variable:
MALLOC_CONF=tcache:false,redzone:true,stats_print:true

jemalloc version is 3.6.0

This is what we are seeing in logs:

<jemalloc>: include/jemalloc/internal/arena.h:508: Failed assertion:
"pageind >= map_bias"

Can you tell us anything about this assertion?
Is there a way this could happen? Is it a possible bug in jemalloc or is it
more likely that this is some random corruption in internal
jemalloc structures?

Thank you.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20150803/41a525f7/attachment.html>

From jasone at canonware.com  Mon Aug 17 15:56:47 2015
From: jasone at canonware.com (Jason Evans)
Date: Mon, 17 Aug 2015 15:56:47 -0700
Subject: cross compiling - how do I figure out the correct value of
	je_cv_static_page_shift
In-Reply-To: <35F6921410093E4CA40D524BD5C18D4C268A72A2@EDXMB57.jdnet.deere.com>
References: <35F6921410093E4CA40D524BD5C18D4C268A72A2@EDXMB57.jdnet.deere.com>
Message-ID: <3DD1CC2A-4D2B-4F90-AE2F-CA53000948EF@canonware.com>

On Jun 12, 2015, at 8:13 AM, Miller Henry <MillerHenry at JohnDeere.com> wrote:
> I?m evaluating jemalloc on my embedded system, which we cross compile to several different processors.  Since I?m cross compiling, configure cannot figure out what the correct value of je_cv_static_page_shift should be.  No surprise, for early tests I just set it to 12 (based solely on some android searches showing a patch to hard code it to 12).  This works for early tests, but if I?m to go production I want the correct value, and I need to leave clear instructions to my successor on how to find this in case we add a new processor in the future.
>  
> How can I figure this out?  Ideally I want a command I can run in a shell, but if I need to build a program I can do that.

This depends on the operating system, so there's no single answer.

As an aside, jemalloc 4.x has the --with-lg-page configure option, so it's a bit simpler now to specify the page size when cross compiling.

Jason


From cferris at google.com  Mon Aug 17 15:57:00 2015
From: cferris at google.com (Christopher Ferris)
Date: Mon, 17 Aug 2015 15:57:00 -0700
Subject: arena cache being reused
In-Reply-To: <441203B4-064C-4C72-BAF2-FB19FE675CB1@canonware.com>
References: <CANtHk4k+u-S8aKF7pvc4o3bS+EQV5djmhKGMhxpSVSze6oRw7g@mail.gmail.com>
	<441203B4-064C-4C72-BAF2-FB19FE675CB1@canonware.com>
Message-ID: <CANtHk4kiDF08sJfc0Fpn4hTeywf_=1GGRMco7g9_i_OtdUStDw@mail.gmail.com>

Sorry, I meant to follow up before the release, but I didn't get a chance.

Yes, it only repros on 4.0.0 since I think this is the first time you've
used the arenas_cache. It's a bit tricky to trigger, since you need to
allocate memory from a pthread_key_destroy function. I don't have a good
test case since I wasn't sure exactly what triggered the path to create the
arenas_cache again. It's also tricky since the memory that gets corrupted
is something in a small bin in my configuration (2 arenas, I also
artificially constrained the number of tcache entries). So it's likely that
most code would never trigger this exact problem.

Christopher

On Mon, Aug 17, 2015 at 3:20 PM, Jason Evans <jasone at canonware.com> wrote:

> On Jul 8, 2015, at 3:42 PM, Christopher Ferris <cferris at google.com> wrote:
> > Using the current version of the dev jemalloc, I found a case where
> jemalloc reuses a previously freed pointer. Specifically, the arena cache
> pointer can get freed, but reused.
> >
> > This can happen when a thread is ending and the key destroy functions
> are being called. If the jemalloc key destroy function is called, the arena
> cache is destroyed. But if another key destroy function is called which
> allocates memory, the old arena cache pointer can be reused, and have the
> arena pointers written to it.
> >
> > I think the fix is to change the arenas_cache_cleanup function to:
> >
> > void
> > arenas_cache_cleanup(tsd_t *tsd)
> > {
> >         arena_t **arenas_cache;
> >
> >         arenas_cache = tsd_arenas_cache_get(tsd);
> >         if (arenas_cache != NULL) {
> >                 bool *arenas_cache_bypassp =
> tsd_arenas_cache_bypassp_get(tsd);
> >                 *arenas_cache_bypassp = true;
> >                 tsd_arenas_cache_set(tsd, NULL);
> >                 a0dalloc(arenas_cache);
> >         }
> > }
> >
> > I believe the bypass has to be set so that another arena cache is not
> allocated since that memory would be leaked since there is not going to be
> another call to the arenas_cache_cleanup function. I think this is the only
> possible way something could be reused when an allocation is made after the
> jemalloc key destroy function is called, but I might have missed something.
> >
> > This might be particular to the fact that my config uses
> pthread_key_create for the tsd data, but it might apply to other configs.
> >
> > Does this solution seem reasonable?
>
> Unfortunately I didn't see this email until after the 4.0.0 release,
> because the mailing lists haven't been delivering email for the past two
> months (ouch).  Does this problem still exist with 4.0.0?
>
> Thanks,
> Jason
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20150817/e440b3d7/attachment.html>

From jasone at canonware.com  Mon Aug 17 15:59:43 2015
From: jasone at canonware.com (Jason Evans)
Date: Mon, 17 Aug 2015 15:59:43 -0700
Subject: How to dump status of jemalloc on Android
In-Reply-To: <BAY179-W37147FC5620D8401E10CC5D78E0@phx.gbl>
References: <BAY179-W37147FC5620D8401E10CC5D78E0@phx.gbl>
Message-ID: <4D08C725-64B7-448A-8C93-8A26F43A21EC@canonware.com>

On Jul 27, 2015, at 2:56 AM, LiHaifeng <omycle at gmail.com> wrote:
> It's known that the jemalloc is adopted by Android. Recently I want to dump some jemalloc status information with the thread exit. Fortunately, the function of status dump has been done by jemalloc.
> 
> After tuned the variable of opt_stats_print into true in malloc_init_hard(), the stats_print_atexit() was registered as an hook for atexit(). But, there is nothing status information dumped when the process exit and there is only the warning on the console like below.
> 
> "W/libc    (  859): WARNING: generic atexit() called from legacy shared library"
> 
> So, how to dump the jemalloc status on Android?

There appears to have been some change to glibc within the past two years that causes stdin/stdout/stderr to be closed before atexit-registered functions run.  To work around this you can directly call malloc_stats_print() directly in your application before it exits.  I ran into this a few days ago on an Ubuntu 15.04 system, and found this related bug report while trying to diagnose the issue:

	https://code.google.com/p/address-sanitizer/issues/detail?id=263

Jason

From jasone at canonware.com  Mon Aug 17 16:02:45 2015
From: jasone at canonware.com (Jason Evans)
Date: Mon, 17 Aug 2015 16:02:45 -0700
Subject: assertion pageind >= map_bias
In-Reply-To: <CA+RAKy7tTFWYg7JNpN4Q9oHZZ=3d6_2e+JhUHzWqafGQfpnpZA@mail.gmail.com>
References: <CA+RAKy7tTFWYg7JNpN4Q9oHZZ=3d6_2e+JhUHzWqafGQfpnpZA@mail.gmail.com>
Message-ID: <118A55BD-81FF-4162-89EF-4D69EB3ADD8C@canonware.com>

On Aug 3, 2015, at 4:02 PM, marko at kevac.org wrote:
> We are using jemalloc in our internal project and we have been experiencing very strange memory corruptions lately, so we decided to build jemalloc with --enable-debug and --enable-fill and give it a try.
> 
> Also, we used this env variable: MALLOC_CONF=tcache:false,redzone:true,stats_print:true
> 
> jemalloc version is 3.6.0
> 
> This is what we are seeing in logs:
> 
> <jemalloc>: include/jemalloc/internal/arena.h:508: Failed assertion: "pageind >= map_bias"
> 
> Can you tell us anything about this assertion?
> Is there a way this could happen? Is it a possible bug in jemalloc or is it more likely that this is some random corruption in internal jemalloc structures?

I can't guess much about the nature of the memory corruption a backtrace through the jemalloc functions.  If you're still experiencing this issue, please post a backtrace and I'll take a look.

Thanks,
Jason

From Paul.Marquess at owmobility.com  Tue Aug 18 05:14:53 2015
From: Paul.Marquess at owmobility.com (Paul Marquess)
Date: Tue, 18 Aug 2015 12:14:53 +0000
Subject: jemalloc coring in je_bitmap_set
In-Reply-To: <CY1PR0501MB11782CF052D618F4CFC1002B95F40@CY1PR0501MB1178.namprd05.prod.outlook.com>
References: <CY1PR0501MB11782CF052D618F4CFC1002B95F40@CY1PR0501MB1178.namprd05.prod.outlook.com>
Message-ID: <CY1PR0501MB1178BCD293432254D59E378595780@CY1PR0501MB1178.namprd05.prod.outlook.com>

I see a reference to a fix for arena_tcache_fill_small and corruption in the 4.0 ChangeLog. Any chance it could be the root cause for this issue?

Paul

-----Original Message-----
From: jemalloc-discuss-bounces at canonware.com [mailto:jemalloc-discuss-bounces at canonware.com] On Behalf Of Paul Marquess
Sent: 31 March 2015 13:49
To: jemalloc-discuss at canonware.com
Subject: jemalloc coring in je_bitmap_set

Lately I've got reports of one of our server applications coring in je_bitmap_set. 

There is a common pattern with the stack traces from all the cores.  Starting at the call to malloc the stack trace is always the same (shown below). The frames leading up to the call to malloc don't show any common pattern, plus there is nothing immediately obvious in the application code that calls malloc. We are running a standard jemalloc 3.6.0 on a 64-bit Redhat 6.4

This issue cannot be reproduced in our test setup, so I'm looking for ideas on how to root cause the issue from the core file.  

Here are details on my analysis to date

#0? 0x00002b997a4a65df in je_bitmap_set (bit=18446744073709551555, 
??? binfo=0x2b997a6d1540 <je_arena_bin_info+768>, bitmap=0x2b999e660010)
??? at include/jemalloc/internal/bitmap.h:101
#1? je_bitmap_sfu (binfo=0x2b997a6d1540 <je_arena_bin_info+768>, 
??? bitmap=0x2b999e660010) at include/jemalloc/internal/bitmap.h:140
#2? arena_run_reg_alloc (bin_info=0x2b997a6d1518 <je_arena_bin_info+728>, 
??? run=0x2b999e660000) at src/arena.c:291
#3? je_arena_tcache_fill_small (arena=0x2b997b07f700, tbin=0x2b99a5406108, 
??? binind=7, prof_accumbytes=<optimized out>) at src/arena.c:1479
#4? 0x00002b997a4c55af in je_tcache_alloc_small_hard (tcache=<optimized out>, 
??? tbin=0x2b99a5406108, binind=<optimized out>) at src/tcache.c:72
#5? 0x00002b997a49a3fd in je_tcache_alloc_small (size=<optimized out>, 
??? tcache=0x2b99a5406000, zero=false)
??? at include/jemalloc/internal/tcache.h:303
#6? je_arena_malloc (try_tcache=true, zero=false, size=<optimized out>, 
??? arena=0x0) at include/jemalloc/internal/arena.h:957
#7? je_imalloct (arena=0x0, try_tcache=true, size=<optimized out>)
??? at include/jemalloc/internal/jemalloc_internal.h:771
#8? je_imalloc (size=<optimized out>)
??? at include/jemalloc/internal/jemalloc_internal.h:780
#9? malloc (size=<optimized out>) at src/jemalloc.c:929

The core is triggered at line 101 of bitmap_set below

88        JEMALLOC_INLINE void
89        bitmap_set(bitmap_t *bitmap, const bitmap_info_t *binfo, size_t bit)
90        {
91                size_t goff;
92                bitmap_t *gp;
93                bitmap_t g;
94        
95                assert(bit < binfo->nbits);
96                assert(bitmap_get(bitmap, binfo, bit) == false);
97                goff = bit >> LG_BITMAP_GROUP_NBITS;
98                gp = &bitmap[goff];
99                g = *gp;
100              assert(g & (1LU << (bit & BITMAP_GROUP_NBITS_MASK)));
101              g ^= 1LU << (bit & BITMAP_GROUP_NBITS_MASK);
       
In all the cores the value of "bit" is 0xffffffffffff. That then results in "g" being an invalid pointer. For example, this is what I see in one of the cores

    (gdb) p bitmap
    $15 = (bitmap_t *) 0x2b999e660010
    (gdb) p gp
    $16 = (bitmap_t *) 0x20002b999e660008
    (gdb) p g
    Cannot access memory at address 0x20002b999e660008

Here is an analysis of how "bit" got set to 0xffffffffffff in bitmap_sfu from the same core file

121	/* sfu: set first unset. */
122	JEMALLOC_INLINE size_t
123	bitmap_sfu(bitmap_t *bitmap, const bitmap_info_t *binfo)
124	{
125		size_t bit;
126		bitmap_t g;
127		unsigned i;
128	
129		assert(bitmap_full(bitmap, binfo) == false);
130	
131		i = binfo->nlevels - 1;
132		g = bitmap[binfo->levels[i].group_offset];
133		bit = ffsl(g) - 1;
134		while (i > 0) {
135			i--;
136			g = bitmap[binfo->levels[i].group_offset + bit];
137			bit = (bit << LG_BITMAP_GROUP_NBITS) + (ffsl(g) - 1);
138		}
139	
140		bitmap_set(bitmap, binfo, bit);
141		return (bit);
142	}


(gdb) p binfo->nlevels
$3 = 2
(gdb) p binfo->levels[1].group_offset
$4 = 2
(gdb) p bitmap[2]
$5 = 1

(gdb) hexdump memory bitmap bitmap+16
00000000  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
00000010  01 00 00 00 00 00 00 00  50 79 eb 08 74 2b 00 00  |........Py..t+..|
00000020  b0 79 eb 08 74 2b 00 00  00 00 00 00 01 00 00 00  |.y..t+..........|
00000030  02 00 00 00 01 00 00 00  01 00 00 00 01 00 00 00  |................|
00000040  b0 02 ea 08 74 2b 00 00  40 18 ea 08 74 2b 00 00  |....t+.. at ...t+..|
00000050  b0 12 ea 08 74 2b 00 00  00 00 00 00 00 00 00 00  |....t+..........|
00000060  00 00 00 00 09 00 00 00  e5 ff ff ff 12 00 00 00  |................|
00000070  02 00 00 00 01 00 00 00  00 00 00 00 00 00 00 00  |................|

Above means that "i" will be 1 at line 131, "g" will be 1 at line 132 and "bit" will be 0 at line 133.

The while loop will run once (because "I" is 1), so "g" is set to 1 at line 136, then bit get set to 0xffffffffffff at line 137.

That's as far as I've got.

Until the start of this week I didn't know the jemalloc code at all, so I'm not sure what my analysis infers about the root cause for the core. Any suggestions about what to check next would be most welcome.

cheers
Paul

_______________________________________________
jemalloc-discuss mailing list
jemalloc-discuss at canonware.com
http://www.canonware.com/mailman/listinfo/jemalloc-discuss

From jasone at canonware.com  Tue Aug 18 08:21:31 2015
From: jasone at canonware.com (Jason Evans)
Date: Tue, 18 Aug 2015 08:21:31 -0700
Subject: jemalloc coring in je_bitmap_set
In-Reply-To: <CY1PR0501MB1178BCD293432254D59E378595780@CY1PR0501MB1178.namprd05.prod.outlook.com>
References: <CY1PR0501MB11782CF052D618F4CFC1002B95F40@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<CY1PR0501MB1178BCD293432254D59E378595780@CY1PR0501MB1178.namprd05.prod.outlook.com>
Message-ID: <E3D8D509-FA64-4A26-88C8-019FDF054ADB@canonware.com>

On Aug 18, 2015, at 5:14 AM, Paul Marquess <Paul.Marquess at owmobility.com> wrote:
> I see a reference to a fix for arena_tcache_fill_small and corruption in the 4.0 ChangeLog. Any chance it could be the root cause for this issue?

It's possible, but the failure mode for that bug depends on failing to map memory (i.e. extreme memory pressure).

Jason


From Paul.Marquess at owmobility.com  Tue Aug 18 08:49:11 2015
From: Paul.Marquess at owmobility.com (Paul Marquess)
Date: Tue, 18 Aug 2015 15:49:11 +0000
Subject: jemalloc coring in je_bitmap_set
In-Reply-To: <E3D8D509-FA64-4A26-88C8-019FDF054ADB@canonware.com>
References: <CY1PR0501MB11782CF052D618F4CFC1002B95F40@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<CY1PR0501MB1178BCD293432254D59E378595780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<E3D8D509-FA64-4A26-88C8-019FDF054ADB@canonware.com>
Message-ID: <CY1PR0501MB11784744EBDDDCA83870062795780@CY1PR0501MB1178.namprd05.prod.outlook.com>

> From: Jason Evans [mailto:jasone at canonware.com] 
> 
> On Aug 18, 2015, at 5:14 AM, Paul Marquess <Paul.Marquess at owmobility.com> wrote:
> > I see a reference to a fix for arena_tcache_fill_small and corruption in the 4.0 ChangeLog. Any chance it could be the root cause for this issue?
> 
> It's possible, but the failure mode for that bug depends on failing to map memory (i.e. extreme memory pressure).

Thanks Jason, 

do you mean a failure in the call to mmap? Assume that isn't necessarily catastrophic (otherwise I assume you would assert straight away).

Is there anything in jemalloc (or other tools) I can do to root cause why that is happening?

cheers
Paul

From jasone at canonware.com  Tue Aug 18 08:59:34 2015
From: jasone at canonware.com (Jason Evans)
Date: Tue, 18 Aug 2015 08:59:34 -0700
Subject: jemalloc coring in je_bitmap_set
In-Reply-To: <CY1PR0501MB11784744EBDDDCA83870062795780@CY1PR0501MB1178.namprd05.prod.outlook.com>
References: <CY1PR0501MB11782CF052D618F4CFC1002B95F40@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<CY1PR0501MB1178BCD293432254D59E378595780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<E3D8D509-FA64-4A26-88C8-019FDF054ADB@canonware.com>
	<CY1PR0501MB11784744EBDDDCA83870062795780@CY1PR0501MB1178.namprd05.prod.outlook.com>
Message-ID: <3AE9D880-8EDD-4D9D-B3A9-DF188B45BC52@canonware.com>

On Aug 18, 2015, at 8:49 AM, Paul Marquess <Paul.Marquess at owmobility.com> wrote:
>> From: Jason Evans [mailto:jasone at canonware.com] 
>> 
>> On Aug 18, 2015, at 5:14 AM, Paul Marquess <Paul.Marquess at owmobility.com> wrote:
>>> I see a reference to a fix for arena_tcache_fill_small and corruption in the 4.0 ChangeLog. Any chance it could be the root cause for this issue?
>> 
>> It's possible, but the failure mode for that bug depends on failing to map memory (i.e. extreme memory pressure).
> 
> do you mean a failure in the call to mmap? Assume that isn't necessarily catastrophic (otherwise I assume you would assert straight away).

Yes, mmap() and sbrk() failure.  It should simply result in malloc() returning NULL, but the arena_tcache_fill_small bug you mentioned caused corruption that would later cause crashes.

> Is there anything in jemalloc (or other tools) I can do to root cause why that is happening?

Valgrind is great.  There's ASAN (address sanitizer) as well.  jemalloc with --enable-debug and MALLOC_CONF=tcache:false can catch quite a few issues as well.

Jason

From Paul.Marquess at owmobility.com  Tue Aug 18 11:53:02 2015
From: Paul.Marquess at owmobility.com (Paul Marquess)
Date: Tue, 18 Aug 2015 18:53:02 +0000
Subject: jemalloc coring in je_bitmap_set
In-Reply-To: <3AE9D880-8EDD-4D9D-B3A9-DF188B45BC52@canonware.com>
References: <CY1PR0501MB11782CF052D618F4CFC1002B95F40@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<CY1PR0501MB1178BCD293432254D59E378595780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<E3D8D509-FA64-4A26-88C8-019FDF054ADB@canonware.com>
	<CY1PR0501MB11784744EBDDDCA83870062795780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<3AE9D880-8EDD-4D9D-B3A9-DF188B45BC52@canonware.com>
Message-ID: <CY1PR0501MB1178055CCC2D1B8EA08C384395780@CY1PR0501MB1178.namprd05.prod.outlook.com>

> From: Jason Evans [mailto:jasone at canonware.com] 
 
> On Aug 18, 2015, at 8:49 AM, Paul Marquess <Paul.Marquess at owmobility.com> wrote:
> >> From: Jason Evans [mailto:jasone at canonware.com] 
> >> 
> >> On Aug 18, 2015, at 5:14 AM, Paul Marquess <Paul.Marquess at owmobility.com> wrote:
> >>> I see a reference to a fix for arena_tcache_fill_small and corruption in the 4.0 ChangeLog. Any chance it could be the root cause for this issue?
> >> 
> >> It's possible, but the failure mode for that bug depends on failing to map memory (i.e. extreme memory pressure).
> > 
> > do you mean a failure in the call to mmap? Assume that isn't necessarily catastrophic (otherwise I assume you would assert straight away).
> 
> Yes, mmap() and sbrk() failure.  It should simply result in malloc() returning NULL, but the arena_tcache_fill_small bug you mentioned caused corruption that would later cause crashes.

Guess we need to wrap jemalloc's malloc and get it to assert when it gets a null. Perhaps get a dump of jemallocs state -- would  the stats interface in jemalloc will still be operational if we are OOM? Alternative is to get the stats from the core --  I see there are a couple of core file postmortem scripts for jemalloc knocking about, but none seem to support 3.6. 

Something else has occurred to me - we had a problem with THP and uninterruptable sleep (~30 seconds) very recently that was fixed by tuning  the swappiness parameter. When researching that I spotted a number of threads that suggested that the combination of THP and jemalloc can result in memory growth.  This thread is an example https://www.digitalocean.com/company/blog/transparent-huge-pages-and-alternative-memory-allocators/ . I know it's too much of a stretch to suggest that this is the root cause of the OOM, but if it does cause memory growth it won't help.

Do you have any feeling whether it is safe to have jemalloc and THP at the same time?


> > Is there anything in jemalloc (or other tools) I can do to root cause why that is happening?
> 
> Valgrind is great.  

Indeed it is, and it is a tool we make frequent use of. Problem is its waaaay to slow. The issue only happens on our live server. We've attempted to trigger the issue with a load test, but it has never happened. 

> There's ASAN (address sanitizer) as well.  

Yep, we've started using that recently. It's found a number of issues for us. Very nice it is too. 

> jemalloc with --enable-debug and MALLOC_CONF=tcache:false can catch quite a few issues as well.

I've just dipped my toe into jemalloc's debug features. Need to research that some more. 

cheers 
Paul

From jasone at canonware.com  Tue Aug 18 12:44:58 2015
From: jasone at canonware.com (Jason Evans)
Date: Tue, 18 Aug 2015 12:44:58 -0700
Subject: jemalloc coring in je_bitmap_set
In-Reply-To: <CY1PR0501MB1178055CCC2D1B8EA08C384395780@CY1PR0501MB1178.namprd05.prod.outlook.com>
References: <CY1PR0501MB11782CF052D618F4CFC1002B95F40@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<CY1PR0501MB1178BCD293432254D59E378595780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<E3D8D509-FA64-4A26-88C8-019FDF054ADB@canonware.com>
	<CY1PR0501MB11784744EBDDDCA83870062795780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<3AE9D880-8EDD-4D9D-B3A9-DF188B45BC52@canonware.com>
	<CY1PR0501MB1178055CCC2D1B8EA08C384395780@CY1PR0501MB1178.namprd05.prod.outlook.com>
Message-ID: <BEA53518-6E01-41A2-99F6-FE1D4BC5137D@canonware.com>

On Aug 18, 2015, at 11:53 AM, Paul Marquess <Paul.Marquess at owmobility.com> wrote:
>> From: Jason Evans [mailto:jasone at canonware.com] 
> 
>> On Aug 18, 2015, at 8:49 AM, Paul Marquess <Paul.Marquess at owmobility.com> wrote:
>>>> From: Jason Evans [mailto:jasone at canonware.com] 
>>>> 
>>>> On Aug 18, 2015, at 5:14 AM, Paul Marquess <Paul.Marquess at owmobility.com> wrote:
>>>>> I see a reference to a fix for arena_tcache_fill_small and corruption in the 4.0 ChangeLog. Any chance it could be the root cause for this issue?
>>>> 
>>>> It's possible, but the failure mode for that bug depends on failing to map memory (i.e. extreme memory pressure).
>>> 
>>> do you mean a failure in the call to mmap? Assume that isn't necessarily catastrophic (otherwise I assume you would assert straight away).
>> 
>> Yes, mmap() and sbrk() failure.  It should simply result in malloc() returning NULL, but the arena_tcache_fill_small bug you mentioned caused corruption that would later cause crashes.
> 
> Guess we need to wrap jemalloc's malloc and get it to assert when it gets a null. Perhaps get a dump of jemallocs state -- would  the stats interface in jemalloc will still be operational if we are OOM? Alternative is to get the stats from the core --  I see there are a couple of core file postmortem scripts for jemalloc knocking about, but none seem to support 3.6.

You might be able to strace and audit the mmap() failures, but an easier solution would be to add an abort() in the known bad code path within arena_tcache_fill_small() so that you know if you've hit the failure mode.

> Something else has occurred to me - we had a problem with THP and uninterruptable sleep (~30 seconds) very recently that was fixed by tuning  the swappiness parameter. When researching that I spotted a number of threads that suggested that the combination of THP and jemalloc can result in memory growth.  This thread is an example https://www.digitalocean.com/company/blog/transparent-huge-pages-and-alternative-memory-allocators/ . I know it's too much of a stretch to suggest that this is the root cause of the OOM, but if it does cause memory growth it won't help.
> 
> Do you have any feeling whether it is safe to have jemalloc and THP at the same time?

I've had pretty poor experience with the mixture even within the past month.  The problem is that at some point (under a day of intermittent benchmarking in all the cases I observed) the kernel gets into a fragmented memory state that it cannot recover from without a reboot, and the only obvious indications are decreased performance and increased page faults.

Jason

From Paul.Marquess at owmobility.com  Tue Aug 18 14:58:15 2015
From: Paul.Marquess at owmobility.com (Paul Marquess)
Date: Tue, 18 Aug 2015 21:58:15 +0000
Subject: jemalloc coring in je_bitmap_set
In-Reply-To: <BEA53518-6E01-41A2-99F6-FE1D4BC5137D@canonware.com>
References: <CY1PR0501MB11782CF052D618F4CFC1002B95F40@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<CY1PR0501MB1178BCD293432254D59E378595780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<E3D8D509-FA64-4A26-88C8-019FDF054ADB@canonware.com>
	<CY1PR0501MB11784744EBDDDCA83870062795780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<3AE9D880-8EDD-4D9D-B3A9-DF188B45BC52@canonware.com>
	<CY1PR0501MB1178055CCC2D1B8EA08C384395780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<BEA53518-6E01-41A2-99F6-FE1D4BC5137D@canonware.com>
Message-ID: <CY1PR0501MB11786171732582017CF4E34495780@CY1PR0501MB1178.namprd05.prod.outlook.com>

> > Do you have any feeling whether it is safe to have jemalloc and THP at the same time?
> 
> I've had pretty poor experience with the mixture even within the past month.  The problem is that at some point (under a day of intermittent benchmarking in all the cases I observed) the kernel gets into a fragmented memory state that it cannot recover from without a reboot, and the only obvious indications are decreased performance and increased page faults.

Do you think that disabling madvise with opt.lg_dirty_mult:-1 allows jemalloc & THP to co-exist without causing other unwanted side-effects?

Paul

From danielmicay at gmail.com  Tue Aug 18 18:59:01 2015
From: danielmicay at gmail.com (Daniel Micay)
Date: Tue, 18 Aug 2015 21:59:01 -0400
Subject: jemalloc coring in je_bitmap_set
In-Reply-To: <CY1PR0501MB11786171732582017CF4E34495780@CY1PR0501MB1178.namprd05.prod.outlook.com>
References: <CY1PR0501MB11782CF052D618F4CFC1002B95F40@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<CY1PR0501MB1178BCD293432254D59E378595780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<E3D8D509-FA64-4A26-88C8-019FDF054ADB@canonware.com>
	<CY1PR0501MB11784744EBDDDCA83870062795780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<3AE9D880-8EDD-4D9D-B3A9-DF188B45BC52@canonware.com>
	<CY1PR0501MB1178055CCC2D1B8EA08C384395780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<BEA53518-6E01-41A2-99F6-FE1D4BC5137D@canonware.com>
	<CY1PR0501MB11786171732582017CF4E34495780@CY1PR0501MB1178.namprd05.prod.outlook.com>
Message-ID: <55D3E2E5.5040107@gmail.com>

On 18/08/15 05:58 PM, Paul Marquess wrote:
>>> Do you have any feeling whether it is safe to have jemalloc and THP at the same time?
>>
>> I've had pretty poor experience with the mixture even within the past month.  The problem is that at some point (under a day of intermittent benchmarking in all the cases I observed) the kernel gets into a fragmented memory state that it cannot recover from without a reboot, and the only obvious indications are decreased performance and increased page faults.
> 
> Do you think that disabling madvise with opt.lg_dirty_mult:-1 allows jemalloc & THP to co-exist without causing other unwanted side-effects?
> 
> Paul

Well, you won't lose huge pages if you've disabled purging. It's going
to increase memory usage but that may not be a problem for you.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20150818/f3f987fe/attachment.sig>

From ingvar at redpill-linpro.com  Wed Aug 19 03:02:05 2015
From: ingvar at redpill-linpro.com (Ingvar Hagelund)
Date: Wed, 19 Aug 2015 12:02:05 +0200
Subject: jemalloc-4.0.0 test suite segfaults on aarch64
Message-ID: <55D4541D.90404@redpill-linpro.com>

I've started wrapping jemalloc-4.0.0 for fedora. aarch64 is now a target
arch for fedora. When sent to the arm builders, the unit/bitmap test
segfaults. Full log here:

http://arm.koji.fedoraproject.org//work/tasks/6832/3126832/build.log

Also note the vast amounts of "warning: left shift count is negative".

Unfortunately, I don't have access to aarch64 hardware myself, so
debugging and testing patches is a bit hard. But I can send scratch
builds to the Fedora arm builders and observe the results.

Ingvar

From jasone at canonware.com  Wed Aug 19 11:44:03 2015
From: jasone at canonware.com (Jason Evans)
Date: Wed, 19 Aug 2015 11:44:03 -0700
Subject: jemalloc-4.0.0 test suite segfaults on aarch64
In-Reply-To: <55D4541D.90404@redpill-linpro.com>
References: <55D4541D.90404@redpill-linpro.com>
Message-ID: <FAE7E94F-3CFE-454A-B37C-67E199054288@canonware.com>

On Aug 19, 2015, at 3:02 AM, Ingvar Hagelund <ingvar at redpill-linpro.com> wrote:
> I've started wrapping jemalloc-4.0.0 for fedora. aarch64 is now a target
> arch for fedora. When sent to the arm builders, the unit/bitmap test
> segfaults. Full log here:
> 
> http://arm.koji.fedoraproject.org//work/tasks/6832/3126832/build.log
> 
> Also note the vast amounts of "warning: left shift count is negative".

This happens with page sizes larger than 8 KiB.  I can test a patch locally by specifying --with-lg-page=16 during configuration.  The segfault is hopefully a side effect of the bit shifting issue (I certainly get test crashes when specifying --with-lg-page=16).

Thanks,
Jason

From david.abdurachmanov at gmail.com  Wed Aug 19 11:53:48 2015
From: david.abdurachmanov at gmail.com (David Abdurachmanov)
Date: Wed, 19 Aug 2015 20:53:48 +0200
Subject: jemalloc-4.0.0 test suite segfaults on aarch64
In-Reply-To: <FAE7E94F-3CFE-454A-B37C-67E199054288@canonware.com>
References: <55D4541D.90404@redpill-linpro.com>
	<FAE7E94F-3CFE-454A-B37C-67E199054288@canonware.com>
Message-ID: <507CCBE8-AA79-4A94-9BE0-404C90B3ADFD@gmail.com>


> On 19 Aug 2015, at 20:44, Jason Evans <jasone at canonware.com> wrote:
> 
> On Aug 19, 2015, at 3:02 AM, Ingvar Hagelund <ingvar at redpill-linpro.com> wrote:
>> I've started wrapping jemalloc-4.0.0 for fedora. aarch64 is now a target
>> arch for fedora. When sent to the arm builders, the unit/bitmap test
>> segfaults. Full log here:
>> 
>> http://arm.koji.fedoraproject.org//work/tasks/6832/3126832/build.log
>> 
>> Also note the vast amounts of "warning: left shift count is negative".
> 
> This happens with page sizes larger than 8 KiB.  I can test a patch locally by specifying --with-lg-page=16 during configuration.  The segfault is hopefully a side effect of the bit shifting issue (I certainly get test crashes when specifying --with-lg-page=16).

Fedora for aarch64 (and ppc64le, I guess) has page size set to 64K. I think,
Ubuntu has 4K pages on aarch64 (at least for now).

I have access to aarch64 machines, thus I could run test suite on demand for
validation/patch testing purposes.

david

From ingvar at redpill-linpro.com  Wed Aug 19 12:46:21 2015
From: ingvar at redpill-linpro.com (Ingvar Hagelund)
Date: Wed, 19 Aug 2015 21:46:21 +0200 (CEST)
Subject: jemalloc-4.0.0 test suite segfaults on aarch64
In-Reply-To: <FAE7E94F-3CFE-454A-B37C-67E199054288@canonware.com>
References: <55D4541D.90404@redpill-linpro.com>
	<FAE7E94F-3CFE-454A-B37C-67E199054288@canonware.com>
Message-ID: <2012790728.131848.1440013581476.JavaMail.zimbra@redpill-linpro.com>

----- On Aug 19, 2015, at 8:44 PM, Jason Evans <jasone at canonware.com> wrote: 

> On Aug 19, 2015, at 3:02 AM, Ingvar Hagelund <ingvar at redpill-linpro.com> wrote:
> > I've started wrapping jemalloc-4.0.0 for fedora. aarch64 is now a target
> > arch for fedora. When sent to the arm builders, the unit/bitmap test
> > segfaults. Full log here:

> > http://arm.koji.fedoraproject.org//work/tasks/6832/3126832/build.log

> > Also note the vast amounts of "warning: left shift count is negative".

> This happens with page sizes larger than 8 KiB.
That's the case here, yes. Fedora 22 on aarch64. 

$ uname -a 
Linux arm64 4.0.4-301.fc22.aarch64 #1 SMP Thu May 21 15:21:42 UTC 2015 aarch64 aarch64 aarch64 GNU/Linux 

$ getconf PAGESIZE 
65536 

> I can test a patch locally by specifying --with-lg-page=16 during configuration.
> The segfault is hopefully a side effect of the bit shifting issue (I certainly
> get test crashes when specifying --with-lg-page=16).
I have got a qemu aarch64 instance running now, so I would happily test patches. 

I throw in a gdb backtrace for good measure 

[ingvar at arm64 jemalloc-4.0.0]$ gdb test/unit/bitmap 
GNU gdb (GDB) Fedora 7.9-11.fc22 
(...snip...) 
This GDB was configured as "aarch64-redhat-linux-gnu". 
(...snip....) 

Reading symbols from test/unit/bitmap...done. 
(gdb) run 
Starting program: /home/ingvar/rpmbuild/BUILD/jemalloc-4.0.0/test/unit/bitmap 
[Thread debugging using libthread_db enabled] 
Using host libthread_db library "/lib64/libthread_db.so.1". 
test_bitmap_size: pass 

Program received signal SIGSEGV, Segmentation fault. 
__GI___pthread_mutex_lock (mutex=mutex at entry=0x840) at pthread_mutex_lock.c:67 
67 unsigned int type = PTHREAD_MUTEX_TYPE_ELISION (mutex); 
(gdb) bt 
#0 __GI___pthread_mutex_lock (mutex=mutex at entry=0x840) at pthread_mutex_lock.c:67 
#1 0x000000000042f704 in jet_malloc_mutex_lock (mutex=0x14ae70840) at include/jemalloc/internal/mutex.h:85 
#2 jet_tcache_bin_flush_small (tsd=tsd at entry=0x3ffb7810008, tcache=tcache at entry=0x3ffb7820000, tbin=tbin at entry=0x3ffb7820020, binind=binind at entry=0, rem=1768846639) at src/tcache.c:115 
#3 0x0000000000408574 in jet_tcache_dalloc_small (binind=0, ptr=0x3ffb7a78f00, tcache=0x3ffb7820000, tsd=0x3ffb7810008) at include/jemalloc/internal/tcache.h:376 
#4 jet_arena_dalloc (tcache=0x3ffb7820000, ptr=0x3ffb7a78f00, tsd=0x3ffb7810008) at include/jemalloc/internal/arena.h:1195 
#5 jet_idalloctm (is_metadata=false, tcache=0x3ffb7820000, ptr=0x3ffb7a78f00, tsd=0x3ffb7810008) at include/jemalloc/internal/jemalloc_internal.h:1005 
#6 jet_iqalloc (tcache=0x3ffb7820000, ptr=0x3ffb7a78f00, tsd=0x3ffb7810008) at include/jemalloc/internal/jemalloc_internal.h:1029 
#7 ifree (tcache=0x3ffb7820000, ptr=0x3ffb7a78f00, tsd=0x3ffb7810008) at src/jemalloc.c:1723 
#8 jet_free (ptr=ptr at entry=0x3ffb7a78f00) at src/jemalloc.c:1817 
#9 0x0000000000401a84 in test_bitmap_init () at test/unit/bitmap.c:34 
#10 0x0000000000434a20 in p_test (t=0x401970 <test_bitmap_init>) at test/src/test.c:84 
#11 0x000003ffb7d1f964 in __libc_start_main (main=0x0, argc=0, argv=0x0, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=<optimized out>) at libc-start.c:289 
#12 0x00000000004016f0 in _start () 
Backtrace stopped: previous frame identical to this frame (corrupt stack?) 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20150819/da12ef57/attachment.html>

From Paul.Marquess at owmobility.com  Wed Aug 19 13:38:28 2015
From: Paul.Marquess at owmobility.com (Paul Marquess)
Date: Wed, 19 Aug 2015 20:38:28 +0000
Subject: jemalloc coring in je_bitmap_set
In-Reply-To: <55D3E2E5.5040107@gmail.com>
References: <CY1PR0501MB11782CF052D618F4CFC1002B95F40@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<CY1PR0501MB1178BCD293432254D59E378595780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<E3D8D509-FA64-4A26-88C8-019FDF054ADB@canonware.com>
	<CY1PR0501MB11784744EBDDDCA83870062795780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<3AE9D880-8EDD-4D9D-B3A9-DF188B45BC52@canonware.com>
	<CY1PR0501MB1178055CCC2D1B8EA08C384395780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<BEA53518-6E01-41A2-99F6-FE1D4BC5137D@canonware.com>
	<CY1PR0501MB11786171732582017CF4E34495780@CY1PR0501MB1178.namprd05.prod.outlook.com>
	<55D3E2E5.5040107@gmail.com>
Message-ID: <CY1PR0501MB1178E0854B2998D50167BED895670@CY1PR0501MB1178.namprd05.prod.outlook.com>

> From: jemalloc-discuss-bounces at canonware.com [mailto:jemalloc-discuss-bounces at canonware.com] On Behalf Of Daniel Micay

> On 18/08/15 05:58 PM, Paul Marquess wrote:
> >>> Do you have any feeling whether it is safe to have jemalloc and THP at the same time?
> >>
> >> I've had pretty poor experience with the mixture even within the past month.  The problem is that at some point (under a day of intermittent benchmarking in all the cases I observed) the kernel gets into a fragmented memory state that it cannot recover from without a reboot, and the only obvious indications are decreased performance and increased page faults.
> > 
> > Do you think that disabling madvise with opt.lg_dirty_mult:-1 allows jemalloc & THP to co-exist without causing other unwanted side-effects?
> > 
> > Paul
> 
> Well, you won't lose huge pages if you've disabled purging. It's going to increase memory usage but that may not be a problem for you.

Thanks Daniel, that's what I was expecting. Just checking if anyone has encountered any nasty surprises (like a hit on performance) with the workaround to get jemalloc & THP to play together.

Paul


From jasone at canonware.com  Wed Aug 19 14:19:34 2015
From: jasone at canonware.com (Jason Evans)
Date: Wed, 19 Aug 2015 14:19:34 -0700
Subject: jemalloc-4.0.0 test suite segfaults on aarch64
In-Reply-To: <2012790728.131848.1440013581476.JavaMail.zimbra@redpill-linpro.com>
References: <55D4541D.90404@redpill-linpro.com>
	<FAE7E94F-3CFE-454A-B37C-67E199054288@canonware.com>
	<2012790728.131848.1440013581476.JavaMail.zimbra@redpill-linpro.com>
Message-ID: <AF1D8539-B4E9-4CB8-80F7-BF9599C8F430@canonware.com>

Fixed:

	https://github.com/jemalloc/jemalloc/commit/5ef33a9f2b9f4fb56553529f7b31f4f5f57ce014

Thanks,
Jason


From ingvar at redpill-linpro.com  Wed Aug 19 23:15:40 2015
From: ingvar at redpill-linpro.com (Ingvar Hagelund)
Date: Thu, 20 Aug 2015 08:15:40 +0200
Subject: jemalloc-4.0.0 test suite segfaults on aarch64
In-Reply-To: <AF1D8539-B4E9-4CB8-80F7-BF9599C8F430@canonware.com>
References: <55D4541D.90404@redpill-linpro.com>
	<FAE7E94F-3CFE-454A-B37C-67E199054288@canonware.com>
	<2012790728.131848.1440013581476.JavaMail.zimbra@redpill-linpro.com>
	<AF1D8539-B4E9-4CB8-80F7-BF9599C8F430@canonware.com>
Message-ID: <55D5708C.4070608@redpill-linpro.com>

Den 19. aug. 2015 23:19, skrev Jason Evans:
> Fixed:
> 
> 	https://github.com/jemalloc/jemalloc/commit/5ef33a9f2b9f4fb56553529f7b31f4f5f57ce014

Excellent! Now the test suite passes with no errors.

Note that gcc still warns about "right shift count is negative".

http://arm.koji.fedoraproject.org//work/tasks/9259/3129259/build.log

Ingvar



From jasone at canonware.com  Wed Aug 19 23:24:46 2015
From: jasone at canonware.com (Jason Evans)
Date: Wed, 19 Aug 2015 23:24:46 -0700
Subject: jemalloc-4.0.0 test suite segfaults on aarch64
In-Reply-To: <55D5708C.4070608@redpill-linpro.com>
References: <55D4541D.90404@redpill-linpro.com>
	<FAE7E94F-3CFE-454A-B37C-67E199054288@canonware.com>
	<2012790728.131848.1440013581476.JavaMail.zimbra@redpill-linpro.com>
	<AF1D8539-B4E9-4CB8-80F7-BF9599C8F430@canonware.com>
	<55D5708C.4070608@redpill-linpro.com>
Message-ID: <24046A19-6302-4A2B-9D46-A0A48BD48DF1@canonware.com>

On Aug 19, 2015, at 11:15 PM, Ingvar Hagelund <ingvar at redpill-linpro.com> wrote:
> Note that gcc still warns about "right shift count is negative".
> 
> http://arm.koji.fedoraproject.org//work/tasks/9259/3129259/build.log

Bummer.  I tested this with clang, which does enough flow control analysis to realize that the negative shifts are unreachable and omit the warnings, but then forgot to check gcc.  I'll revert to #if..#elseif..#else..#endif.

Thanks,
Jason

From ingvar at redpill-linpro.com  Thu Aug 20 00:34:59 2015
From: ingvar at redpill-linpro.com (Ingvar Hagelund)
Date: Thu, 20 Aug 2015 09:34:59 +0200
Subject: jemalloc-4.0.0 on el5 and el6: undefined reference to `clock_gettime'
Message-ID: <55D58323.2010104@redpill-linpro.com>

When compiling jemalloc-4.0.0 on rhel5 or rhel6, the linker stops with
"undefined reference to `clock_gettime'"

Adding "-lrt" to LDFLAGS gets around this, but perhaps it could have
been picked up automatically?

Regards,
Ingvar


el6$ gcc -o test/unit/atomic test/unit/atomic.o src/jemalloc.jet.o
src/arena.jet.o src/atomic.jet.o src/base.jet.o src/bitmap.jet.o
src/chunk.jet.o src/chunk_dss.jet.o src/chunk_mmap.jet.o src/ckh.jet.o
src/ctl.jet.o src/extent.jet.o src/hash.jet.o src/huge.jet.o
src/mb.jet.o src/mutex.jet.o src/pages.jet.o src/prof.jet.o
src/quarantine.jet.o src/rtree.jet.o src/stats.jet.o src/tcache.jet.o
src/util.jet.o src/tsd.jet.o src/valgrind.jet.o test/src/btalloc.unit.o
test/src/btalloc_0.unit.o test/src/btalloc_1.unit.o test/src/math.unit.o
test/src/mtx.unit.o test/src/mq.unit.o test/src/SFMT.unit.o
test/src/test.unit.o test/src/thd.unit.o test/src/timer.unit.o
-Wl,-rpath,lib  -lpthread -lm
test/src/timer.unit.o: In function `timer_stop':
/builddir/build/BUILD/jemalloc-4.0.0/test/src/timer.c:27: undefined
reference to `clock_gettime'
test/src/timer.unit.o: In function `timer_start':
/builddir/build/BUILD/jemalloc-4.0.0/test/src/timer.c:14: undefined
reference to `clock_gettime'
/builddir/build/BUILD/jemalloc-4.0.0/test/src/timer.c:14: undefined
reference to `clock_gettime'
collect2: ld returned 1 exit status
make: *** [test/unit/atomic] Error 1

From danielmicay at gmail.com  Thu Aug 20 00:36:45 2015
From: danielmicay at gmail.com (Daniel Micay)
Date: Thu, 20 Aug 2015 03:36:45 -0400
Subject: jemalloc-4.0.0 on el5 and el6: undefined reference to
	`clock_gettime'
In-Reply-To: <55D58323.2010104@redpill-linpro.com>
References: <55D58323.2010104@redpill-linpro.com>
Message-ID: <55D5838D.7080305@gmail.com>

On 20/08/15 03:34 AM, Ingvar Hagelund wrote:
> When compiling jemalloc-4.0.0 on rhel5 or rhel6, the linker stops with
> "undefined reference to `clock_gettime'"
> 
> Adding "-lrt" to LDFLAGS gets around this, but perhaps it could have
> been picked up automatically?
> 
> Regards,
> Ingvar
> 
> 
> el6$ gcc -o test/unit/atomic test/unit/atomic.o src/jemalloc.jet.o
> src/arena.jet.o src/atomic.jet.o src/base.jet.o src/bitmap.jet.o
> src/chunk.jet.o src/chunk_dss.jet.o src/chunk_mmap.jet.o src/ckh.jet.o
> src/ctl.jet.o src/extent.jet.o src/hash.jet.o src/huge.jet.o
> src/mb.jet.o src/mutex.jet.o src/pages.jet.o src/prof.jet.o
> src/quarantine.jet.o src/rtree.jet.o src/stats.jet.o src/tcache.jet.o
> src/util.jet.o src/tsd.jet.o src/valgrind.jet.o test/src/btalloc.unit.o
> test/src/btalloc_0.unit.o test/src/btalloc_1.unit.o test/src/math.unit.o
> test/src/mtx.unit.o test/src/mq.unit.o test/src/SFMT.unit.o
> test/src/test.unit.o test/src/thd.unit.o test/src/timer.unit.o
> -Wl,-rpath,lib  -lpthread -lm
> test/src/timer.unit.o: In function `timer_stop':
> /builddir/build/BUILD/jemalloc-4.0.0/test/src/timer.c:27: undefined
> reference to `clock_gettime'
> test/src/timer.unit.o: In function `timer_start':
> /builddir/build/BUILD/jemalloc-4.0.0/test/src/timer.c:14: undefined
> reference to `clock_gettime'
> /builddir/build/BUILD/jemalloc-4.0.0/test/src/timer.c:14: undefined
> reference to `clock_gettime'
> collect2: ld returned 1 exit status
> make: *** [test/unit/atomic] Error 1

Yeah, the issue would be that clock_gettime was moved to libc in newer
versions of libc so -lrt wasn't added for the tests.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20150820/1eb1893a/attachment.sig>

From ingvar at redpill-linpro.com  Thu Aug 20 08:04:06 2015
From: ingvar at redpill-linpro.com (Ingvar Hagelund)
Date: Thu, 20 Aug 2015 17:04:06 +0200 (CEST)
Subject: jemalloc-4.0.0 test suite segfaults on aarch64
In-Reply-To: <24046A19-6302-4A2B-9D46-A0A48BD48DF1@canonware.com>
References: <55D4541D.90404@redpill-linpro.com>
	<FAE7E94F-3CFE-454A-B37C-67E199054288@canonware.com>
	<2012790728.131848.1440013581476.JavaMail.zimbra@redpill-linpro.com>
	<AF1D8539-B4E9-4CB8-80F7-BF9599C8F430@canonware.com>
	<55D5708C.4070608@redpill-linpro.com>
	<24046A19-6302-4A2B-9D46-A0A48BD48DF1@canonware.com>
Message-ID: <12795197.186710.1440083046542.JavaMail.zimbra@redpill-linpro.com>

----- On Aug 20, 2015, at 8:24 AM, Jason Evans <jasone at canonware.com> wrote: 

> On Aug 19, 2015, at 11:15 PM, Ingvar Hagelund <ingvar at redpill-linpro.com> wrote:
> > Note that gcc still warns about "right shift count is negative".

> > http://arm.koji.fedoraproject.org//work/tasks/9259/3129259/build.log

> Bummer. I tested this with clang, which does enough flow control analysis to
> realize that the negative shifts are unreachable and omit the warnings, but
> then forgot to check gcc. I'll revert to #if..#elseif..#else..#endif.
That's only cosmetics, I guess. 

FYI, I've ran builds including the test suite successfully on the fedora and epel targets, that is ppc, ppc64, ppcel64, armv7, aarch64, i686, and x86_64 

Ingvar 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20150820/e4751d6d/attachment.html>

From jasone at canonware.com  Fri Aug 21 09:39:11 2015
From: jasone at canonware.com (Jason Evans)
Date: Fri, 21 Aug 2015 09:39:11 -0700
Subject: jemalloc-4.0.0 on el5 and el6: undefined reference to
	`clock_gettime'
In-Reply-To: <55D5838D.7080305@gmail.com>
References: <55D58323.2010104@redpill-linpro.com> <55D5838D.7080305@gmail.com>
Message-ID: <8928A812-8A2E-4E89-A93B-C5BC49D87538@canonware.com>

On Aug 20, 2015, at 12:36 AM, Daniel Micay <danielmicay at gmail.com> wrote:
> On 20/08/15 03:34 AM, Ingvar Hagelund wrote:
>> When compiling jemalloc-4.0.0 on rhel5 or rhel6, the linker stops with
>> "undefined reference to `clock_gettime'"
>> 
>> Adding "-lrt" to LDFLAGS gets around this, but perhaps it could have
>> been picked up automatically?
>> 
>> [...]
> 
> Yeah, the issue would be that clock_gettime was moved to libc in newer
> versions of libc so -lrt wasn't added for the tests.

This issue is now being tracked at:

	https://github.com/jemalloc/jemalloc/issues/257

Thanks,
Jason

From jasone at canonware.com  Fri Aug 21 12:35:53 2015
From: jasone at canonware.com (Jason Evans)
Date: Fri, 21 Aug 2015 12:35:53 -0700
Subject: arena cache being reused
In-Reply-To: <CANtHk4kiDF08sJfc0Fpn4hTeywf_=1GGRMco7g9_i_OtdUStDw@mail.gmail.com>
References: <CANtHk4k+u-S8aKF7pvc4o3bS+EQV5djmhKGMhxpSVSze6oRw7g@mail.gmail.com>
	<441203B4-064C-4C72-BAF2-FB19FE675CB1@canonware.com>
	<CANtHk4kiDF08sJfc0Fpn4hTeywf_=1GGRMco7g9_i_OtdUStDw@mail.gmail.com>
Message-ID: <6A643699-E6FC-477A-B708-B7F19D8E6915@canonware.com>

Integrated:

	https://github.com/jemalloc/jemalloc/commit/45e9f66c280e1ba8bebf7bed387a43bc9e45536d

I was able to trigger the bug and verify your fix by slightly modifying the tsd test.

Thanks,
Jason

> On Aug 17, 2015, at 3:57 PM, Christopher Ferris <cferris at google.com> wrote:
> 
> Sorry, I meant to follow up before the release, but I didn't get a chance.
> 
> Yes, it only repros on 4.0.0 since I think this is the first time you've used the arenas_cache. It's a bit tricky to trigger, since you need to allocate memory from a pthread_key_destroy function. I don't have a good test case since I wasn't sure exactly what triggered the path to create the arenas_cache again. It's also tricky since the memory that gets corrupted is something in a small bin in my configuration (2 arenas, I also artificially constrained the number of tcache entries). So it's likely that most code would never trigger this exact problem.
> 
> Christopher
> 
> On Mon, Aug 17, 2015 at 3:20 PM, Jason Evans <jasone at canonware.com> wrote:
> On Jul 8, 2015, at 3:42 PM, Christopher Ferris <cferris at google.com> wrote:
> > Using the current version of the dev jemalloc, I found a case where jemalloc reuses a previously freed pointer. Specifically, the arena cache pointer can get freed, but reused.
> >
> > This can happen when a thread is ending and the key destroy functions are being called. If the jemalloc key destroy function is called, the arena cache is destroyed. But if another key destroy function is called which allocates memory, the old arena cache pointer can be reused, and have the arena pointers written to it.
> >
> > I think the fix is to change the arenas_cache_cleanup function to:
> >
> > void
> > arenas_cache_cleanup(tsd_t *tsd)
> > {
> >         arena_t **arenas_cache;
> >
> >         arenas_cache = tsd_arenas_cache_get(tsd);
> >         if (arenas_cache != NULL) {
> >                 bool *arenas_cache_bypassp = tsd_arenas_cache_bypassp_get(tsd);
> >                 *arenas_cache_bypassp = true;
> >                 tsd_arenas_cache_set(tsd, NULL);
> >                 a0dalloc(arenas_cache);
> >         }
> > }
> >
> > I believe the bypass has to be set so that another arena cache is not allocated since that memory would be leaked since there is not going to be another call to the arenas_cache_cleanup function. I think this is the only possible way something could be reused when an allocation is made after the jemalloc key destroy function is called, but I might have missed something.
> >
> > This might be particular to the fact that my config uses pthread_key_create for the tsd data, but it might apply to other configs.
> >
> > Does this solution seem reasonable?
> 
> Unfortunately I didn't see this email until after the 4.0.0 release, because the mailing lists haven't been delivering email for the past two months (ouch).  Does this problem still exist with 4.0.0?
> 
> Thanks,
> Jason
> 


From roel.vandepaar at percona.com  Mon Aug 24 00:58:26 2015
From: roel.vandepaar at percona.com (Roel Van de Paar)
Date: Mon, 24 Aug 2015 17:58:26 +1000
Subject: Semi-dual use of dynamic and static jemalloc
Message-ID: <CAGQTitOSXHB0dMVVe00GtjM+Za8xXOJdnxCuYgbN=svjBedS8w@mail.gmail.com>

Hi

I have a question in regards semi-dual use of dynamic and static jemalloc.

What happens if jemalloc is LD_PRELOAD'ed for an executable where such
executable uses a .so library, which in turn is statically linked with
jemalloc?

Does this result in two jemalloc instances running, each managing part of
heap, neither having a complete view of the system etc.?

Use case example;
LD_PRELOAD....jemalloc... mysqld       # where msyqld uses TokuDB .so lib
and this lib has jemalloc statically linked.

Thanks

-- 

Kind Regards,
God Bless,
-- 
Roel Van de Paar, CMDBA/CMDEV Senior QA Lead, Percona
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20150824/e8d1fe41/attachment.html>

From fw at deneb.enyo.de  Mon Aug 24 12:13:25 2015
From: fw at deneb.enyo.de (Florian Weimer)
Date: Mon, 24 Aug 2015 21:13:25 +0200
Subject: Semi-dual use of dynamic and static jemalloc
In-Reply-To: <CAGQTitOSXHB0dMVVe00GtjM+Za8xXOJdnxCuYgbN=svjBedS8w@mail.gmail.com>
	(Roel Van de Paar's message of "Mon, 24 Aug 2015 17:58:26 +1000")
References: <CAGQTitOSXHB0dMVVe00GtjM+Za8xXOJdnxCuYgbN=svjBedS8w@mail.gmail.com>
Message-ID: <87oahw5wkq.fsf@mid.deneb.enyo.de>

* Roel Van de Paar:

> What happens if jemalloc is LD_PRELOAD'ed for an executable where such
> executable uses a .so library, which in turn is statically linked with
> jemalloc?

That depends on what kind of symbols the libary exports.  What does
?eu-readelf -s? or ?readelf -W -s? show?  If jemalloc symbols are
listed there, quite bad things can happen.

From roel.vandepaar at percona.com  Mon Aug 24 17:24:59 2015
From: roel.vandepaar at percona.com (Roel Van de Paar)
Date: Tue, 25 Aug 2015 10:24:59 +1000
Subject: Semi-dual use of dynamic and static jemalloc
In-Reply-To: <87oahw5wkq.fsf@mid.deneb.enyo.de>
References: <CAGQTitOSXHB0dMVVe00GtjM+Za8xXOJdnxCuYgbN=svjBedS8w@mail.gmail.com>
	<87oahw5wkq.fsf@mid.deneb.enyo.de>
Message-ID: <CAGQTitOngB5xK9hPcTVNUnWkCX6jysvkKopxy4t6PhqfAyN7Ag@mail.gmail.com>

Hi Florian,

Thank you for the reply. My reply inline.

On Tue, Aug 25, 2015 at 5:13 AM, Florian Weimer <fw at deneb.enyo.de> wrote:

> * Roel Van de Paar:
>
> > What happens if jemalloc is LD_PRELOAD'ed for an executable where such
> > executable uses a .so library, which in turn is statically linked with
> > jemalloc?
>
> That depends on what kind of symbols the libary exports.  What does
> ?eu-readelf -s? or ?readelf -W -s? show?  If jemalloc symbols are
> listed there, quite bad things can happen.


[roel at localhost Percona-Server-5.6.25-rel73.2-f9f2b02.Linux.x86_64-debug]$
readelf -W -s ./lib/mysql/plugin/ha_tokudb.so | grep jemalloc
   219: 000000000048ed90     4 OBJECT  LOCAL  DEFAULT   27
_ZL21tokudb_check_jemalloc
   220: 000000000048d4e0    64 OBJECT  LOCAL  DEFAULT   26
_ZL27mysql_sysvar_check_jemalloc
   833: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS jemalloc.pic.o
   840: 000000000009d710    94 FUNC    LOCAL  DEFAULT   11
jemalloc_constructor
  8370: 000000000009d0d0    90 FUNC    LOCAL  DEFAULT   11
je_jemalloc_prefork
  8494: 000000000009d010    89 FUNC    LOCAL  DEFAULT   11
je_jemalloc_postfork_child
  8659: 000000000009d070    89 FUNC    LOCAL  DEFAULT   11
je_jemalloc_postfork_parent

Are these jemalloc symbols?

Also, anyone any idea on the other questions too?

-- 

Kind Regards,
God Bless,
-- 
Roel Van de Paar, CMDBA/CMDEV Senior QA Lead, Percona
Tel: +61 2 8004 1288 (UTC+10)
Mob: +61 427 141 635 (UTC+10)
Skype: percona.rvandepaar
http://www.percona.com/services.html

Looking for Replication with Data Consistency?
Try Percona XtraDB Cluster
<http://www.percona.com/software/percona-xtradb-cluster>!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20150825/998fdf97/attachment.html>

From anshul.kundra at hcl.com  Tue Aug 25 23:08:17 2015
From: anshul.kundra at hcl.com (Anshul Kundra)
Date: Wed, 26 Aug 2015 06:08:17 +0000
Subject: jemalloc-queries
Message-ID: <SIXPR04MB0682EEAC6DD7CBA386BE8BD6F6600@SIXPR04MB0682.apcprd04.prod.outlook.com>

Hi,


I am studying jemalloc design so that this design can be used in server based application. Please provide some initial references related to metadata management of each memory allocation of any size in jemalloc.


1.  Is it possible to move the metadata allocation (Internal data structures for each arena a1, a2 .... narenas) from single arena "a0"?

Example:

I have two memory chunks (A & B )or blocks of size  1GB each. One memory chunk A is used to hold metadata information (excluding chunk headers) for each memory request done from memory block B. If memory chunk A cant be able to hold more metadata then  a new memory block of same size 1 GB  is allocated (A1, A2........ An') and same is for B which will

Whether this strategy will work, if arena a0 will be used to hold metadata requests and all the other to serve memory requests. I am also finding out another solution but still not sure whether it works or not, Please see some description


For every Arena allocate two different chunks one to hold metadata information of small size requests and large size requests are already maintained in tree.


2.  Please provide some more details or references related to size class implementation, If  user want to customize the size class granularity to 1MB, 2MB instead of bytes, KB's what other factors need to consider during customization.


3. Is it possible to maintain chunk header separately instead of start of chunk?.


Please correct me if there is any gap in understanding the design of jemalloc and feasibility to club jemalloc with server application.


Thanks & Best Regards,
Anshul Kundra


::DISCLAIMER::
----------------------------------------------------------------------------------------------------------------------------------------------------

The contents of this e-mail and any attachment(s) are confidential and intended for the named recipient(s) only.
E-mail transmission is not guaranteed to be secure or error-free as information could be intercepted, corrupted,
lost, destroyed, arrive late or incomplete, or may contain viruses in transmission. The e mail and its contents
(with or without referred errors) shall therefore not attach any liability on the originator or HCL or its affiliates.
Views or opinions, if any, presented in this email are solely those of the author and may not necessarily reflect the
views or opinions of HCL or its affiliates. Any form of reproduction, dissemination, copying, disclosure, modification,
distribution and / or publication of this message without the prior written consent of authorized representative of
HCL is strictly prohibited. If you have received this email in error please delete it and notify the sender immediately.
Before opening any email and/or attachments, please check them for viruses and other defects.

----------------------------------------------------------------------------------------------------------------------------------------------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20150826/8f5bcf4f/attachment.html>

From mardikiran at gmail.com  Tue Aug 25 23:30:24 2015
From: mardikiran at gmail.com (kiran mardi)
Date: Wed, 26 Aug 2015 12:00:24 +0530
Subject: regarding jemalloc crash
Message-ID: <CABoxPgmEdpJfV8Xnskkoha_GbeDMkVD9LE5XpRvbrKuK3=pW_A@mail.gmail.com>

Hi all,

I am working on Android TV making jemalloc enabled, configured with 16
arenas.

I see the below error when one of my application tried for a malloc.

* #00 pc 00017ac0  /system/lib/libc.so (pthread_mutex_lock+7)*
*    #01 pc 0004f41b  /system/lib/libc.so (je_tcache_bin_flush_small+78)*
*    #02 pc 0004f6cd  /system/lib/libc.so (je_tcache_event_hard+52)*
*    #03 pc 0004b0a9  /system/lib/libc.so (je_malloc+556)*
*    #04 pc 00012cef  /system/lib/libc.so (malloc+10)*
*    #05 pc 0000ed83  /system/lib/libutils.so
(android::SharedBuffer::alloc(unsigned int)+6)*
*    #06 pc 000114d1  /system/lib/libutils.so
(android::VectorImpl::_shrink(unsigned int, unsigned int)+100)*
*    #07 pc 00011555  /system/lib/libutils.so
(android::VectorImpl::removeItemsAt(unsigned int, unsigned int)+12)*

don't know what is the issue. your help is appreciated.

let me know if you need any more logs regarding the crash.

-- 
regards,
kiran mardi
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20150826/e6166afb/attachment.html>

From roel.vandepaar at percona.com  Mon Aug 31 16:40:12 2015
From: roel.vandepaar at percona.com (Roel Van de Paar)
Date: Tue, 1 Sep 2015 09:40:12 +1000
Subject: Semi-dual use of dynamic and static jemalloc
In-Reply-To: <CAGQTitOngB5xK9hPcTVNUnWkCX6jysvkKopxy4t6PhqfAyN7Ag@mail.gmail.com>
References: <CAGQTitOSXHB0dMVVe00GtjM+Za8xXOJdnxCuYgbN=svjBedS8w@mail.gmail.com>
	<87oahw5wkq.fsf@mid.deneb.enyo.de>
	<CAGQTitOngB5xK9hPcTVNUnWkCX6jysvkKopxy4t6PhqfAyN7Ag@mail.gmail.com>
Message-ID: <CAGQTitNaLz1d4b9eicEy=Hzd7zX8ikcLe_HE0=oFXZGU6zPDEA@mail.gmail.com>

Hi Florian, Others,

Any ideas/suggestions? Thank you

On Tue, Aug 25, 2015 at 10:24 AM, Roel Van de Paar <
roel.vandepaar at percona.com> wrote:

> Hi Florian,
>
> Thank you for the reply. My reply inline.
>
> On Tue, Aug 25, 2015 at 5:13 AM, Florian Weimer <fw at deneb.enyo.de> wrote:
>
>> * Roel Van de Paar:
>>
>> > What happens if jemalloc is LD_PRELOAD'ed for an executable where such
>> > executable uses a .so library, which in turn is statically linked with
>> > jemalloc?
>>
>> That depends on what kind of symbols the libary exports.  What does
>> ?eu-readelf -s? or ?readelf -W -s? show?  If jemalloc symbols are
>> listed there, quite bad things can happen.
>
>
> [roel at localhost
> Percona-Server-5.6.25-rel73.2-f9f2b02.Linux.x86_64-debug]$ readelf -W -s
> ./lib/mysql/plugin/ha_tokudb.so | grep jemalloc
>    219: 000000000048ed90     4 OBJECT  LOCAL  DEFAULT   27
> _ZL21tokudb_check_jemalloc
>    220: 000000000048d4e0    64 OBJECT  LOCAL  DEFAULT   26
> _ZL27mysql_sysvar_check_jemalloc
>    833: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS jemalloc.pic.o
>    840: 000000000009d710    94 FUNC    LOCAL  DEFAULT   11
> jemalloc_constructor
>   8370: 000000000009d0d0    90 FUNC    LOCAL  DEFAULT   11
> je_jemalloc_prefork
>   8494: 000000000009d010    89 FUNC    LOCAL  DEFAULT   11
> je_jemalloc_postfork_child
>   8659: 000000000009d070    89 FUNC    LOCAL  DEFAULT   11
> je_jemalloc_postfork_parent
>
> Are these jemalloc symbols?
>
> Also, anyone any idea on the other questions too?
>
> --
>
> Kind Regards,
> God Bless,
> --
> Roel Van de Paar, CMDBA/CMDEV Senior QA Lead, Percona
> Tel: +61 2 8004 1288 (UTC+10)
> Mob: +61 427 141 635 (UTC+10)
> Skype: percona.rvandepaar
> http://www.percona.com/services.html
>
> Looking for Replication with Data Consistency?
> Try Percona XtraDB Cluster
> <http://www.percona.com/software/percona-xtradb-cluster>!
>



-- 

Kind Regards,
God Bless,
-- 
Roel Van de Paar, CMDBA/CMDEV Senior QA Lead, Percona
Tel: +61 2 8004 1288 (UTC+10)
Mob: +61 427 141 635 (UTC+10)
Skype: percona.rvandepaar
http://www.percona.com/services.html

Looking for Replication with Data Consistency?
Try Percona XtraDB Cluster
<http://www.percona.com/software/percona-xtradb-cluster>!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20150901/a89148ad/attachment.html>

From roel.vandepaar at percona.com  Mon Aug 31 16:52:02 2015
From: roel.vandepaar at percona.com (Roel Van de Paar)
Date: Tue, 1 Sep 2015 09:52:02 +1000
Subject: Semi-dual use of dynamic and static jemalloc
In-Reply-To: <CAGQTitNaLz1d4b9eicEy=Hzd7zX8ikcLe_HE0=oFXZGU6zPDEA@mail.gmail.com>
References: <CAGQTitOSXHB0dMVVe00GtjM+Za8xXOJdnxCuYgbN=svjBedS8w@mail.gmail.com>
	<87oahw5wkq.fsf@mid.deneb.enyo.de>
	<CAGQTitOngB5xK9hPcTVNUnWkCX6jysvkKopxy4t6PhqfAyN7Ag@mail.gmail.com>
	<CAGQTitNaLz1d4b9eicEy=Hzd7zX8ikcLe_HE0=oFXZGU6zPDEA@mail.gmail.com>
Message-ID: <CAGQTitNNkVuxYEWb7WNAqt0O+NYDyVRmJj0wRqPqoAphGQ9eTw@mail.gmail.com>

Also adding a full list here

$ readelf -W -s ./lib/mysql/plugin/ha_tokudb.so | egrep 'malloc|free'
    20: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND bitmap_free
   131: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND my_free
   224: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND my_malloc
   282: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND my_hash_free
   396: 000000000019d88e    37 FUNC    GLOBAL DEFAULT   11
_Z30toku_mempool_get_next_free_ptrPK7mempool
   432: 00000000001041c6    73 FUNC    GLOBAL DEFAULT   11
_ZN11block_table24verify_no_free_blocknumsEv
   457: 00000000001d441c   838 FUNC    GLOBAL DEFAULT   11
_Z20toku_xmalloc_alignedmm
   542: 00000000000c5fbd    26 FUNC    GLOBAL DEFAULT   11
db_env_set_func_free
   563: 0000000000198028   158 FUNC    GLOBAL DEFAULT   11
_ZN7bn_data29mempool_malloc_and_update_dmtEmPPv
   603: 000000000019b20e   199 FUNC    WEAK   DEFAULT   11
_ZN4toku3dmtI13klpair_structPS1_NS_16klpair_dmtwriterEE25node_malloc_and_set_valueERKS3_
   631: 0000000000159c50   138 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP14file_map_tupleS2_Lb0EE11node_mallocEv
   649: 0000000000129a76    26 FUNC    WEAK   DEFAULT   11
_ZN4toku21scoped_malloc_alignedD1Ev
   664: 00000000001123c6   386 FUNC    GLOBAL DEFAULT   11
_ZN14cachefile_list15free_stale_dataEP7evictor
   680: 0000000000103fae   460 FUNC    GLOBAL DEFAULT   11
_ZN11block_table23_free_blocknum_unlockedEP10blocknum_sP2ftb
   682: 00000000001bae6c    42 FUNC    GLOBAL DEFAULT   11
_Z11pqueue_freeP11ft_pqueue_t
   693: 0000000000103440    98 FUNC    GLOBAL DEFAULT   11
_ZN11block_table29_translation_prevents_freeingEPNS_11translationE10blocknum_sPNS_22block_translation_pairE
   716: 00000000001d4bf9    26 FUNC    GLOBAL DEFAULT   11
_Z23toku_malloc_usable_sizePv
   741: 00000000001033dc    65 FUNC    GLOBAL DEFAULT   11
_ZN11block_table10block_freeEm
   752: 0000000000132dc8    68 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtI20referenced_xid_tuplePS1_Lb0EE9node_freeEj
   756: 0000000000103ef8   182 FUNC    GLOBAL DEFAULT   11
_ZN11block_table29_free_blocknum_in_translationEPNS_11translationE10blocknum_s
   833: 00000000001a4d80   562 FUNC    GLOBAL DEFAULT   11
_ZN8memarena17malloc_from_arenaEm
   902: 00000000001d3f36   453 FUNC    GLOBAL DEFAULT   11 _Z9toku_freePv
   921: 00000000001a18e4   254 FUNC    GLOBAL DEFAULT   11
_Z23toku_scoped_malloc_initv
   975: 00000000001a1e92    86 FUNC    WEAK   DEFAULT   11
_ZNK4toku8tl_stack14get_free_spaceEv
   978: 0000000000497688     8 OBJECT  GLOBAL DEFAULT   27 malloc_conf
  1057: 00000000001054c6    18 FUNC    WEAK   DEFAULT   11
_ZNK4toku13scoped_malloc3getEv
  1064: 00000000001937c6    41 FUNC    GLOBAL DEFAULT   11
_Z23toku_malloc_in_rollbackP17rollback_log_nodem
  1071: 00000000001d4c7d    32 FUNC    GLOBAL DEFAULT   11
_Z20toku_set_func_mallocPFPvmE
  1103: 000000000013332c   138 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP7tokutxnS2_Lb0EE11node_mallocEv
  1118: 0000000000498340     8 OBJECT  GLOBAL DEFAULT   27 malloc_message
  1147: 000000000048ea28     8 OBJECT  GLOBAL DEFAULT   26 __free_hook
  1218: 00000000001d66b6    26 FUNC    GLOBAL DEFAULT   11 _Z9os_mallocm
  1246: 00000000001154a6   138 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP9cachefileS2_Lb0EE11node_mallocEv
  1251: 00000000001a17fa   150 FUNC    GLOBAL DEFAULT   11
_ZN4toku13scoped_mallocC1Em
  1294: 00000000000a4430  1410 FUNC    GLOBAL DEFAULT   11 free
  1366: 00000000001a1890    84 FUNC    GLOBAL DEFAULT   11
_ZN4toku13scoped_mallocD2Ev
  1464: 0000000000129932   306 FUNC    WEAK   DEFAULT   11
_ZN4toku21scoped_malloc_alignedC2Emm
  1472: 000000000010330a   121 FUNC    GLOBAL DEFAULT   11
_ZN11block_table27_is_valid_freeable_blocknumEPNS_11translationE10blocknum_s
  1523: 000000000009d2b0     5 FUNC    GLOBAL DEFAULT   11
malloc_stats_print
  1558: 00000000001a19f2   266 FUNC    GLOBAL DEFAULT   11
_Z30toku_scoped_malloc_destroy_setv
  1562: 000000000010417a    75 FUNC    GLOBAL DEFAULT   11
_ZN11block_table13free_blocknumEP10blocknum_sP2ftb
  1671: 00000000001d67e1    26 FUNC    GLOBAL DEFAULT   11 _Z7os_freePv
  1683: 00000000001a1afc    82 FUNC    GLOBAL DEFAULT   11
_Z30toku_scoped_malloc_destroy_keyv
  1697: 0000000000099dcc    82 FUNC    WEAK   DEFAULT   11 _ZN6String4freeEv
  1711: 000000000012af86   128 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIiiLb1EE11node_mallocEv
  1733: 000000000018a45c    68 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIiiLb1EE9node_freeEj
  1760: 0000000000129a64    18 FUNC    WEAK   DEFAULT   11
_ZNK4toku21scoped_malloc_aligned3getEv
  1802: 00000000001951f2   138 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP2ftS2_Lb0EE11node_mallocEv
  1864: 00000000001d4c9d    21 FUNC    GLOBAL DEFAULT   11
_Z26toku_set_func_xmalloc_onlyPFPvmE
  1901: 0000000000160d2a    38 FUNC    GLOBAL DEFAULT   11
_Z13toku_ule_freeP3ule
  1940: 0000000000133dfc   138 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtI20referenced_xid_tuplePS1_Lb0EE11node_mallocEv
  1990: 0000000000180c22    79 FUNC    GLOBAL DEFAULT   11
_Z16toku_ftnode_freePP6ftnode
  2000: 00000000001d40fb   801 FUNC    GLOBAL DEFAULT   11 _Z12toku_xmallocm
  2028: 0000000000133b26    68 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP7tokutxnS2_Lb0EE9node_freeEj
  2035: 000000000009aaf6    14 FUNC    WEAK   DEFAULT   11
_ZN7handler28free_foreign_key_create_infoEPc
  2052: 0000000000103384    88 FUNC    GLOBAL DEFAULT   11
_ZN11block_table31_verify_valid_freeable_blocknumEPNS_11translationE10blocknum_s
  2158: 00000000001b4f34   104 FUNC    GLOBAL DEFAULT   11
_ZN15block_allocator11_trace_freeEm
  2169: 00000000000d2eb6   138 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP9__toku_dbS2_Lb0EE11node_mallocEv
  2193: 00000000001d2cb3   978 FUNC    GLOBAL DEFAULT   11 _Z11toku_mallocm
  2211: 000000000019d8c5    32 FUNC    GLOBAL DEFAULT   11
_Z26toku_mempool_get_free_sizePK7mempool
  2234: 0000000000129a76    26 FUNC    WEAK   DEFAULT   11
_ZN4toku21scoped_malloc_alignedD2Ev
  2250: 00000000000d545e   142 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtI17txn_lt_key_rangesS1_Lb0EE11node_mallocEv
  2284: 000000000019dac0   238 FUNC    GLOBAL DEFAULT   11
_Z18toku_mempool_mfreeP7mempoolPvm
  2447: 000000000019cd70   111 FUNC    WEAK   DEFAULT   11
_ZN4toku3dmtI13klpair_structPS1_NS_16klpair_dmtwriterEE9node_freeERKNS_12dmt_internal7subtreeE
  2451: 00000000001d3085  1005 FUNC    GLOBAL DEFAULT   11
_Z19toku_malloc_alignedmm
  2501: 00000000001d66d0    72 FUNC    GLOBAL DEFAULT   11
_Z17os_malloc_alignedmm
  2515: 000000000009e5b0  5253 FUNC    GLOBAL DEFAULT   11 mallocx
  2607: 0000000000104210   244 FUNC    GLOBAL DEFAULT   11
_ZN11block_table21free_unused_blocknumsE10blocknum_s
  2616: 000000000048ea30     8 OBJECT  GLOBAL DEFAULT   26 __malloc_hook
  2623: 00000000000a0440  1930 FUNC    GLOBAL DEFAULT   11 malloc
  2628: 00000000000c5f89    26 FUNC    GLOBAL DEFAULT   11
db_env_set_func_malloc
  2636: 00000000001d4cb2    21 FUNC    GLOBAL DEFAULT   11
_Z25toku_set_func_malloc_onlyPFPvmE
  2685: 0000000000139b3d    81 FUNC    GLOBAL DEFAULT   11
_Z25toku_logger_free_logfilesPPci
  2715: 0000000000189c88   128 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIiiLb0EE11node_mallocEv
  2754: 00000000001a1890    84 FUNC    GLOBAL DEFAULT   11
_ZN4toku13scoped_mallocD1Ev
  2783: 00000000000d3238    68 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP9__toku_dbS2_Lb0EE9node_freeEj
  2798: 00000000001597f0    68 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP14file_map_tupleS2_Lb0EE9node_freeEj
  2813: 00000000001a17fa   150 FUNC    GLOBAL DEFAULT   11
_ZN4toku13scoped_mallocC2Em
  2863: 00000000001a19e2    16 FUNC    GLOBAL DEFAULT   11
_Z26toku_scoped_malloc_destroyv
  2878: 000000000019d8f7   457 FUNC    GLOBAL DEFAULT   11
_Z19toku_mempool_mallocP7mempoolm
  2943: 00000000001b4414   274 FUNC    GLOBAL DEFAULT   11
_ZN15block_allocator10free_blockEm
  2947: 0000000000129932   306 FUNC    WEAK   DEFAULT   11
_ZN4toku21scoped_malloc_alignedC1Emm
  2969: 000000000009d130   175 FUNC    GLOBAL DEFAULT   11
malloc_usable_size
  3016: 00000000000fcac9    38 FUNC    GLOBAL DEFAULT   11
_Z12toku_ft_freeP2ft
  3075: 00000000001d67fb   133 FUNC    GLOBAL DEFAULT   11
_Z21os_malloc_usable_sizePKv
  3107: 000000000016f159   590 FUNC    GLOBAL DEFAULT   11
_Z33toku_log_free_log_entry_resourcesP9log_entry
  3169: 0000000000115284    68 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP9cachefileS2_Lb0EE9node_freeEj
  3179: 00000000001d4d11    21 FUNC    GLOBAL DEFAULT   11
_Z18toku_set_func_freePFvPvE
   114: 00000000000607af    34 FUNC    LOCAL  DEFAULT   11
_ZL16tokudb_my_mallocmi
   116: 0000000000060809    33 FUNC    LOCAL  DEFAULT   11
_ZL14tokudb_my_freePv
   118: 000000000006084c   702 FUNC    LOCAL  DEFAULT   11
_ZL22tokudb_my_multi_mallociz
   219: 000000000048ed90     4 OBJECT  LOCAL  DEFAULT   27
_ZL21tokudb_check_jemalloc
   220: 000000000048d4e0    64 OBJECT  LOCAL  DEFAULT   26
_ZL27mysql_sysvar_check_jemalloc
   235: 0000000000062c3f   206 FUNC    LOCAL  DEFAULT   11
_ZL21free_key_and_col_infoP19st_key_and_col_info
   239: 0000000000062fa2   797 FUNC    LOCAL  DEFAULT   11
_ZL10free_shareP12TOKUDB_SHARE
   240: 00000000001e9b96    11 OBJECT  LOCAL  DEFAULT   13
_ZZL10free_shareP12TOKUDB_SHAREE12__FUNCTION__
   830: 00000000001eb470     8 OBJECT  LOCAL  DEFAULT   13
_ZZL43tokudb_report_fractal_tree_block_map_for_dbPK10__toku_dbtS1_P5TABLEP3THDE12size_is_free
   832: 00000000001eb480     8 OBJECT  LOCAL  DEFAULT   13
_ZZL43tokudb_report_fractal_tree_block_map_for_dbPK10__toku_dbtS1_P5TABLEP3THDE13freelist_null
   833: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS jemalloc.pic.o
   834: 000000000009c420  3007 FUNC    LOCAL  DEFAULT   11 malloc_conf_init
   836: 000000000009d3f0   793 FUNC    LOCAL  DEFAULT   11 malloc_init_hard
   838: 000000000048f180     1 OBJECT  LOCAL  DEFAULT   27
malloc_initialized
   839: 000000000048f1c8     8 OBJECT  LOCAL  DEFAULT   27
malloc_initializer
   840: 000000000009d710    94 FUNC    LOCAL  DEFAULT   11
jemalloc_constructor
   872: 00000000000a9830  1080 FUNC    LOCAL  DEFAULT   11
arena_bin_malloc_hard
   894: 00000000000ad690     6 FUNC    LOCAL  DEFAULT   11 opt_xmalloc_ctl
   940: 00000000000ae2e0    98 FUNC    LOCAL  DEFAULT   11
config_xmalloc_ctl
   966: 00000000000aefb0   231 FUNC    LOCAL  DEFAULT   11
stats_arenas_i_lruns_j_nmalloc_ctl
   974: 00000000000af730   231 FUNC    LOCAL  DEFAULT   11
stats_arenas_i_bins_j_nmalloc_ctl
   978: 00000000000afad0   215 FUNC    LOCAL  DEFAULT   11
stats_arenas_i_large_nmalloc_ctl
   982: 00000000000afe50   215 FUNC    LOCAL  DEFAULT   11
stats_arenas_i_small_nmalloc_ctl
   993: 00000000000b07d0   183 FUNC    LOCAL  DEFAULT   11
stats_huge_nmalloc_ctl
  1405: 00000000001f036b    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIP9__toku_dbS2_Lb0EE11node_mallocEvE12__FUNCTION__
  1407: 00000000001f03f0    10 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIP9__toku_dbS2_Lb0EE9node_freeEjE12__FUNCTION__
  1500: 00000000001f0e33    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtI17txn_lt_key_rangesS1_Lb0EE11node_mallocEvE12__FUNCTION__
  1676: 00000000000db31d    81 FUNC    LOCAL  DEFAULT   11
_ZL11free_inamesPPci
  1677: 00000000000db36e   201 FUNC    LOCAL  DEFAULT   11
_ZL21free_loader_resourcesP13__toku_loader
  1678: 00000000000db437    45 FUNC    LOCAL  DEFAULT   11
_ZL11free_loaderP13__toku_loader
  1918: 00000000000e1990   225 FUNC    LOCAL  DEFAULT   11
_ZL22free_indexer_resourcesP14__toku_indexer
  1919: 00000000000e1a71    53 FUNC    LOCAL  DEFAULT   11
_ZL12free_indexerP14__toku_indexer
  2178: 00000000001f58b0    10 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIPNS_8locktreeES2_Lb0EE9node_freeEjE12__FUNCTION__
  2179: 00000000001f5851    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIPNS_8locktreeES2_Lb0EE11node_mallocEvE12__FUNCTION__
  2252: 00000000001f639a    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIPNS_12lock_requestES2_Lb0EE11node_mallocEvE12__FUNCTION__
  2254: 00000000001f63f0    10 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIPNS_12lock_requestES2_Lb0EE9node_freeEjE12__FUNCTION__
  2370: 00000000001f7653    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIPNS_18txnid_range_bufferES2_Lb0EE11node_mallocEvE12__FUNCTION__
  2372: 00000000001f7690    10 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIPNS_18txnid_range_bufferES2_Lb0EE9node_freeEjE12__FUNCTION__
  2586: 00000000000fd193    38 FUNC    LOCAL  DEFAULT   11
_ZL7ft_freeP9cachefilePv
  2807: 00000000001fb320    28 OBJECT  LOCAL  DEFAULT   13
_ZZN11block_table27_is_valid_freeable_blocknumEPNS_11translationE10blocknum_sE12__FUNCTION__
  2808: 00000000001fb340    32 OBJECT  LOCAL  DEFAULT   13
_ZZN11block_table31_verify_valid_freeable_blocknumEPNS_11translationE10blocknum_sE12__FUNCTION__
  2813: 00000000001fb3f0    30 OBJECT  LOCAL  DEFAULT   13
_ZZN11block_table29_free_blocknum_in_translationEPNS_11translationE10blocknum_sE12__FUNCTION__
  2814: 00000000001fb410    24 OBJECT  LOCAL  DEFAULT   13
_ZZN11block_table23_free_blocknum_unlockedEP10blocknum_sP2ftbE12__FUNCTION__
  2815: 00000000001fb430    25 OBJECT  LOCAL  DEFAULT   13
_ZZN11block_table24verify_no_free_blocknumsEvE12__FUNCTION__
  2816: 00000000001fb450    22 OBJECT  LOCAL  DEFAULT   13
_ZZN11block_table21free_unused_blocknumsE10blocknum_sE12__FUNCTION__
  2839: 00000000001fb060     8 OBJECT  LOCAL  DEFAULT   13
_ZL13freelist_null
  2840: 00000000001fb068     8 OBJECT  LOCAL  DEFAULT   13 _ZL12size_is_free
  2952: 0000000000107b5a   416 FUNC    LOCAL  DEFAULT   11
_ZL20cachetable_free_pairP6ctpair
  3073: 00000000001fd1d0    16 OBJECT  LOCAL  DEFAULT   13
_ZZN14cachefile_list15free_stale_dataEP7evictorE12__FUNCTION__
  3085: 00000000001fd110    10 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIP9cachefileS2_Lb0EE9node_freeEjE12__FUNCTION__
  3086: 00000000001fd0e7    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIP9cachefileS2_Lb0EE11node_mallocEvE12__FUNCTION__
  3484: 0000000000206090    22 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku21scoped_malloc_alignedC1EmmE12__FUNCTION__
  3589: 00000000002062ba    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIiiLb1EE11node_mallocEvE12__FUNCTION__
  3738: 0000000000207670    10 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtI20referenced_xid_tuplePS1_Lb0EE9node_freeEjE12__FUNCTION__
  3739: 0000000000207863    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIP7tokutxnS2_Lb0EE11node_mallocEvE12__FUNCTION__
  3741: 0000000000207880    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtImmLb0EE11node_mallocEvE12__FUNCTION__
  3742: 00000000002079a0    10 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIP7tokutxnS2_Lb0EE9node_freeEjE12__FUNCTION__
  3743: 00000000002079c0    10 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtImmLb0EE9node_freeEjE12__FUNCTION__
  3745: 0000000000207643    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtI20referenced_xid_tuplePS1_Lb0EE11node_mallocEvE12__FUNCTION__
  4215: 000000000014cdad   137 FUNC    LOCAL  DEFAULT   11
_ZL34ftnode_fetch_callback_and_free_bfeP9cachefileP6ctpairi10blocknum_sjPPvS5_P11pair_attr_sPiS4_
  4216: 000000000014ce36    97 FUNC    LOCAL  DEFAULT   11
_ZL31ftnode_pf_callback_and_free_bfePvS_S_iP11pair_attr_s
  4503: 000000000020d080    10 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIP14file_map_tupleS2_Lb0EE9node_freeEjE12__FUNCTION__
  4505: 000000000020d04c    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIP14file_map_tupleS2_Lb0EE11node_mallocEvE12__FUNCTION__
  5020: 0000000000166d00    10 FUNC    LOCAL  DEFAULT   11
_ZL15toku_free_TXNIDm
  5021: 0000000000166d0a    23 FUNC    LOCAL  DEFAULT   11
_ZL20toku_free_TXNID_PAIR12txnid_pair_s
  5022: 0000000000166d21    10 FUNC    LOCAL  DEFAULT   11
_ZL13toku_free_LSN10__toku_lsn
  5023: 0000000000166d2b    10 FUNC    LOCAL  DEFAULT   11
_ZL18toku_free_uint64_tm
  5024: 0000000000166d35     9 FUNC    LOCAL  DEFAULT   11
_ZL18toku_free_uint32_tj
  5025: 0000000000166d3e    11 FUNC    LOCAL  DEFAULT   11
_ZL17toku_free_uint8_th
  5026: 0000000000166d49     9 FUNC    LOCAL  DEFAULT   11
_ZL17toku_free_FILENUM7FILENUM
  5027: 0000000000166d52    10 FUNC    LOCAL  DEFAULT   11
_ZL18toku_free_BLOCKNUM10blocknum_s
  5028: 0000000000166d5c    11 FUNC    LOCAL  DEFAULT   11
_ZL14toku_free_boolb
  5029: 0000000000166d67    26 FUNC    LOCAL  DEFAULT   11
_ZL14toku_free_XIDPP13toku_xa_xid_s
  5030: 0000000000166d81    38 FUNC    LOCAL  DEFAULT   11
_ZL20toku_free_BYTESTRING10BYTESTRING
  5031: 0000000000166da7    38 FUNC    LOCAL  DEFAULT   11
_ZL18toku_free_FILENUMS8FILENUMS
  5103: 000000000016e918    46 FUNC    LOCAL  DEFAULT   11
_ZL50toku_log_free_log_entry_begin_checkpoint_resourcesP24logtype_begin_checkpoint
  5104: 000000000016e946    74 FUNC    LOCAL  DEFAULT   11
_ZL48toku_log_free_log_entry_end_checkpoint_resourcesP22logtype_end_checkpoint
  5105: 000000000016e990    81 FUNC    LOCAL  DEFAULT   11
_ZL44toku_log_free_log_entry_fassociate_resourcesP18logtype_fassociate
  5106: 000000000016e9e1   195 FUNC    LOCAL  DEFAULT   11
_ZL44toku_log_free_log_entry_xstillopen_resourcesP18logtype_xstillopen
  5107: 000000000016eaa4   188 FUNC    LOCAL  DEFAULT   11
_ZL52toku_log_free_log_entry_xstillopenprepared_resourcesP26logtype_xstillopenprepared
  5108: 000000000016eb60    60 FUNC    LOCAL  DEFAULT   11
_ZL40toku_log_free_log_entry_xbegin_resourcesP14logtype_xbegin
  5109: 000000000016eb9c    37 FUNC    LOCAL  DEFAULT   11
_ZL41toku_log_free_log_entry_xcommit_resourcesP15logtype_xcommit
  5110: 000000000016ebc1    53 FUNC    LOCAL  DEFAULT   11
_ZL42toku_log_free_log_entry_xprepare_resourcesP16logtype_xprepare
  5111: 000000000016ebf6    37 FUNC    LOCAL  DEFAULT   11
_ZL40toku_log_free_log_entry_xabort_resourcesP14logtype_xabort
  5112: 000000000016ec1b   142 FUNC    LOCAL  DEFAULT   11
_ZL41toku_log_free_log_entry_fcreate_resourcesP15logtype_fcreate
  5113: 000000000016eca9    63 FUNC    LOCAL  DEFAULT   11
_ZL39toku_log_free_log_entry_fopen_resourcesP13logtype_fopen
  5114: 000000000016ece8    49 FUNC    LOCAL  DEFAULT   11
_ZL40toku_log_free_log_entry_fclose_resourcesP14logtype_fclose
  5115: 000000000016ed19    51 FUNC    LOCAL  DEFAULT   11
_ZL41toku_log_free_log_entry_fdelete_resourcesP15logtype_fdelete
  5116: 000000000016ed4c    93 FUNC    LOCAL  DEFAULT   11
_ZL44toku_log_free_log_entry_enq_insert_resourcesP18logtype_enq_insert
  5117: 000000000016eda9    93 FUNC    LOCAL  DEFAULT   11
_ZL57toku_log_free_log_entry_enq_insert_no_overwrite_resourcesP31logtype_enq_insert_no_overwrite
  5118: 000000000016ee06    72 FUNC    LOCAL  DEFAULT   11
_ZL48toku_log_free_log_entry_enq_delete_any_resourcesP22logtype_enq_delete_any
  5119: 000000000016ee4e   114 FUNC    LOCAL  DEFAULT   11
_ZL53toku_log_free_log_entry_enq_insert_multiple_resourcesP27logtype_enq_insert_multiple
  5120: 000000000016eec0   114 FUNC    LOCAL  DEFAULT   11
_ZL53toku_log_free_log_entry_enq_delete_multiple_resourcesP27logtype_enq_delete_multiple
  5121: 000000000016ef32    51 FUNC    LOCAL  DEFAULT   11
_ZL41toku_log_free_log_entry_comment_resourcesP15logtype_comment
  5122: 000000000016ef65    30 FUNC    LOCAL  DEFAULT   11
_ZL51toku_log_free_log_entry_shutdown_up_to_19_resourcesP25logtype_shutdown_up_to_19
  5123: 000000000016ef83    46 FUNC    LOCAL  DEFAULT   11
_ZL42toku_log_free_log_entry_shutdown_resourcesP16logtype_shutdown
  5124: 000000000016efb1    72 FUNC    LOCAL  DEFAULT   11
_ZL38toku_log_free_log_entry_load_resourcesP12logtype_load
  5125: 000000000016eff9    58 FUNC    LOCAL  DEFAULT   11
_ZL43toku_log_free_log_entry_hot_index_resourcesP17logtype_hot_index
  5126: 000000000016f033    93 FUNC    LOCAL  DEFAULT   11
_ZL44toku_log_free_log_entry_enq_update_resourcesP18logtype_enq_update
  5127: 000000000016f090    90 FUNC    LOCAL  DEFAULT   11
_ZL53toku_log_free_log_entry_enq_updatebroadcast_resourcesP27logtype_enq_updatebroadcast
  5128: 000000000016f0ea   111 FUNC    LOCAL  DEFAULT   11
_ZL52toku_log_free_log_entry_change_fdescriptor_resourcesP26logtype_change_fdescriptor
  5734: 0000000000215853    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIiiLb0EE11node_mallocEvE12__FUNCTION__
  5736: 0000000000215910    10 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIiiLb1EE9node_freeEjE12__FUNCTION__
  5739: 00000000002158e2    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIiiLb1EE11node_mallocEvE12__FUNCTION__
  6272: 0000000000219903    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIP2ftS2_Lb0EE11node_mallocEvE12__FUNCTION__
  6463: 000000000021b820    30 OBJECT  LOCAL  DEFAULT   13
_ZZN7bn_data29mempool_malloc_and_update_dmtEmPPvE12__FUNCTION__
  6488: 000000000021b770    26 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3dmtI13klpair_structPS1_NS_16klpair_dmtwriterEE25node_malloc_and_set_valueERKS3_E12__FUNCTION__
  6531: 000000000021bd50    20 OBJECT  LOCAL  DEFAULT   13
_ZZ19toku_mempool_mallocP7mempoolmE12__FUNCTION__
  6532: 000000000021bd70    19 OBJECT  LOCAL  DEFAULT   13
_ZZ18toku_mempool_mfreeP7mempoolPvmE12__FUNCTION__
  6645: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS scoped_malloc.cc
  6661: 000000000021d824    15 OBJECT  LOCAL  DEFAULT   13
_ZZNK4toku8tl_stack14get_free_spaceEvE12__FUNCTION__
  6663: 000000000021d890    24 OBJECT  LOCAL  DEFAULT   13
_ZZ23toku_scoped_malloc_initvE12__FUNCTION__
  6664: 000000000021d8d0    31 OBJECT  LOCAL  DEFAULT   13
_ZZ30toku_scoped_malloc_destroy_setvE12__FUNCTION__
  6665: 000000000021d8f0    31 OBJECT  LOCAL  DEFAULT   13
_ZZ30toku_scoped_malloc_destroy_keyvE12__FUNCTION__
  6715: 000000000021e180    18 OBJECT  LOCAL  DEFAULT   13
_ZZN8memarena17malloc_from_arenaEmE12__FUNCTION__
  6787: 00000000001a6e72   166 FUNC    LOCAL  DEFAULT   11
_ZL12free_counterm
  6788: 000000000021ec90    13 OBJECT  LOCAL  DEFAULT   13
_ZZL12free_countermE12__FUNCTION__
  7031: 00000000002207c1    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtIPNS_3wfg4nodeES3_Lb0EE11node_mallocEvE12__FUNCTION__
  7082: 0000000000220fd0    10 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtImmLb0EE9node_freeEjE12__FUNCTION__
  7083: 0000000000220f87    12 OBJECT  LOCAL  DEFAULT   13
_ZZN4toku3omtImmLb0EE11node_mallocEvE12__FUNCTION__
  7267: 0000000000222f0e    11 OBJECT  LOCAL  DEFAULT   13
_ZZN15block_allocator10free_blockEmE12__FUNCTION__
  7806: 00000000001cc0f0    66 FUNC    LOCAL  DEFAULT   11
free_properties.isra.0
  7891: 00000000004955a8     8 OBJECT  LOCAL  DEFAULT   27 _ZL8t_malloc
  7892: 00000000004955b0     8 OBJECT  LOCAL  DEFAULT   27
_ZL16t_malloc_aligned
  7893: 00000000004955b8     8 OBJECT  LOCAL  DEFAULT   27 _ZL9t_xmalloc
  7894: 00000000004955c0     8 OBJECT  LOCAL  DEFAULT   27
_ZL17t_xmalloc_aligned
  7895: 00000000004955c8     8 OBJECT  LOCAL  DEFAULT   27 _ZL6t_free
  7902: 00000000001d2afb    40 FUNC    LOCAL  DEFAULT   11
_ZL21my_malloc_usable_sizePv
  7907: 000000000022f078    13 OBJECT  LOCAL  DEFAULT   13
_ZZ12toku_xmallocmE12__FUNCTION__
  7908: 000000000022f090    21 OBJECT  LOCAL  DEFAULT   13
_ZZ20toku_xmalloc_alignedmmE12__FUNCTION__
  7932: 00000000004975e8     8 OBJECT  LOCAL  DEFAULT   27
_ZL14malloc_stats_f
  7960: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS os_malloc.cc
  7965: 0000000000497620     8 OBJECT  LOCAL  DEFAULT   27
_ZL20malloc_usable_size_f
  8058: 00000000000ee676   138 FUNC    LOCAL  DEFAULT   11
_ZN4toku3omtIPNS_12lock_requestES2_Lb0EE11node_mallocEv
  8078: 00000000000eb662    68 FUNC    LOCAL  DEFAULT   11
_ZN4toku3omtIPNS_8locktreeES2_Lb0EE9node_freeEj
  8081: 00000000000c20d0     2 FUNC    LOCAL  DEFAULT   11
je_malloc_tsd_no_cleanup
  8096: 00000000000b6490     5 FUNC    LOCAL  DEFAULT   11
je_malloc_mutex_postfork_parent
  8120: 00000000000c0d80    39 FUNC    LOCAL  DEFAULT   11 je_malloc_write
  8200: 00000000000c20e0    29 FUNC    LOCAL  DEFAULT   11
je_malloc_tsd_cleanup_register
  8220: 00000000000f59f6    68 FUNC    LOCAL  DEFAULT   11
_ZN4toku3omtIPNS_18txnid_range_bufferES2_Lb0EE9node_freeEj
  8235: 00000000000b5f70    21 FUNC    LOCAL  DEFAULT   11 je_huge_malloc
  8249: 00000000000eb8be   138 FUNC    LOCAL  DEFAULT   11
_ZN4toku3omtIPNS_8locktreeES2_Lb0EE11node_mallocEv
  8266: 000000000009fc90     7 FUNC    LOCAL  DEFAULT   11 je_a0malloc
  8272: 00000000000c1f60   139 FUNC    LOCAL  DEFAULT   11 je_malloc_cprintf
  8299: 0000000000133b6a    68 FUNC    LOCAL  DEFAULT   11
_ZN4toku3omtImmLb0EE9node_freeEj
  8310: 00000000000b64b0   148 FUNC    LOCAL  DEFAULT   11
je_malloc_mutex_init
  8337: 00000000000ee9b0    68 FUNC    LOCAL  DEFAULT   11
_ZN4toku3omtIPNS_12lock_requestES2_Lb0EE9node_freeEj
  8350: 00000000000c1ec0   156 FUNC    LOCAL  DEFAULT   11 je_malloc_printf
  8368: 00000000000c2110    91 FUNC    LOCAL  DEFAULT   11
je_malloc_tsd_dalloc
  8370: 000000000009d0d0    90 FUNC    LOCAL  DEFAULT   11
je_jemalloc_prefork
  8396: 00000000000c1070  3487 FUNC    LOCAL  DEFAULT   11
je_malloc_vsnprintf
  8459: 00000000001ae0c4   138 FUNC    LOCAL  DEFAULT   11
_ZN4toku3omtIPNS_3wfg4nodeES3_Lb0EE11node_mallocEv
  8484: 00000000000b64a0     5 FUNC    LOCAL  DEFAULT   11
je_malloc_mutex_prefork
  8494: 000000000009d010    89 FUNC    LOCAL  DEFAULT   11
je_jemalloc_postfork_child
  8509: 00000000001337ec   138 FUNC    LOCAL  DEFAULT   11
_ZN4toku3omtImmLb0EE11node_mallocEv
  8518: 00000000004982c8     8 OBJECT  LOCAL  DEFAULT   27 je_huge_nmalloc
  8533: 000000000009c3a0   118 FUNC    LOCAL  DEFAULT   11 je_a0free
  8559: 00000000000f56bc   138 FUNC    LOCAL  DEFAULT   11
_ZN4toku3omtIPNS_18txnid_range_bufferES2_Lb0EE11node_mallocEv
  8587: 00000000001e1f07    38 FUNC    LOCAL  DEFAULT   11 zcfree
  8598: 00000000000f05e6   107 FUNC    LOCAL  DEFAULT   11
_ZN4toku8treenode4freeEPS0_
  8621: 000000000048f173     1 OBJECT  LOCAL  DEFAULT   27 je_opt_xmalloc
  8633: 00000000001ad044    42 FUNC    LOCAL  DEFAULT   11
_ZN4toku3wfg4node4freeEPS1_
  8634: 00000000000c2170   169 FUNC    LOCAL  DEFAULT   11
je_malloc_tsd_malloc
  8659: 000000000009d070    89 FUNC    LOCAL  DEFAULT   11
je_jemalloc_postfork_parent
  8662: 00000000000c2100    11 FUNC    LOCAL  DEFAULT   11
je_malloc_tsd_boot
  8673: 00000000001c62f0    37 FUNC    LOCAL  DEFAULT   11 lzma_free
  8684: 00000000000b6550    55 FUNC    LOCAL  DEFAULT   11
je_malloc_mutex_postfork_child
  8691: 00000000000a9f60   909 FUNC    LOCAL  DEFAULT   11
je_arena_malloc_small
  8726: 00000000000c0db0   585 FUNC    LOCAL  DEFAULT   11
je_malloc_strtoumax
  8737: 00000000000a7ee0   250 FUNC    LOCAL  DEFAULT   11
je_arena_malloc_large
  8739: 00000000000c1e10   163 FUNC    LOCAL  DEFAULT   11
je_malloc_vcprintf
  8754: 00000000000c1ff0   139 FUNC    LOCAL  DEFAULT   11
je_malloc_snprintf
  8805: 00000000001d4c7d    32 FUNC    GLOBAL DEFAULT   11
_Z20toku_set_func_mallocPFPvmE
  8819: 0000000000129a76    26 FUNC    WEAK   DEFAULT   11
_ZN4toku21scoped_malloc_alignedD2Ev
  8836: 00000000001a4d80   562 FUNC    GLOBAL DEFAULT   11
_ZN8memarena17malloc_from_arenaEm
  8848: 00000000001d67e1    26 FUNC    GLOBAL DEFAULT   11 _Z7os_freePv
  8852: 000000000009d130   175 FUNC    GLOBAL DEFAULT   11
malloc_usable_size
  8949: 0000000000103440    98 FUNC    GLOBAL DEFAULT   11
_ZN11block_table29_translation_prevents_freeingEPNS_11translationE10blocknum_sPNS_22block_translation_pairE
  8972: 0000000000133b26    68 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP7tokutxnS2_Lb0EE9node_freeEj
  8976: 000000000019d8f7   457 FUNC    GLOBAL DEFAULT   11
_Z19toku_mempool_mallocP7mempoolm
  8992: 00000000001937c6    41 FUNC    GLOBAL DEFAULT   11
_Z23toku_malloc_in_rollbackP17rollback_log_nodem
  9002: 000000000018a45c    68 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIiiLb1EE9node_freeEj
  9008: 00000000001d441c   838 FUNC    GLOBAL DEFAULT   11
_Z20toku_xmalloc_alignedmm
  9040: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND bitmap_free
  9047: 00000000001a1afc    82 FUNC    GLOBAL DEFAULT   11
_Z30toku_scoped_malloc_destroy_keyv
  9162: 0000000000160d2a    38 FUNC    GLOBAL DEFAULT   11
_Z13toku_ule_freeP3ule
  9168: 0000000000103fae   460 FUNC    GLOBAL DEFAULT   11
_ZN11block_table23_free_blocknum_unlockedEP10blocknum_sP2ftb
  9194: 00000000001a1890    84 FUNC    GLOBAL DEFAULT   11
_ZN4toku13scoped_mallocD1Ev
  9239: 0000000000103ef8   182 FUNC    GLOBAL DEFAULT   11
_ZN11block_table29_free_blocknum_in_translationEPNS_11translationE10blocknum_s
  9342: 00000000001054c6    18 FUNC    WEAK   DEFAULT   11
_ZNK4toku13scoped_malloc3getEv
  9400: 00000000001033dc    65 FUNC    GLOBAL DEFAULT   11
_ZN11block_table10block_freeEm
  9444: 00000000001597f0    68 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP14file_map_tupleS2_Lb0EE9node_freeEj
  9447: 000000000009d2b0     5 FUNC    GLOBAL DEFAULT   11
malloc_stats_print
  9455: 00000000001d40fb   801 FUNC    GLOBAL DEFAULT   11 _Z12toku_xmallocm
  9530: 00000000000a0440  1930 FUNC    GLOBAL DEFAULT   11 malloc
  9545: 00000000001a1e92    86 FUNC    WEAK   DEFAULT   11
_ZNK4toku8tl_stack14get_free_spaceEv
  9607: 00000000001d4cb2    21 FUNC    GLOBAL DEFAULT   11
_Z25toku_set_func_malloc_onlyPFPvmE
  9654: 000000000019cd70   111 FUNC    WEAK   DEFAULT   11
_ZN4toku3dmtI13klpair_structPS1_NS_16klpair_dmtwriterEE9node_freeERKNS_12dmt_internal7subtreeE
  9667: 000000000019b20e   199 FUNC    WEAK   DEFAULT   11
_ZN4toku3dmtI13klpair_structPS1_NS_16klpair_dmtwriterEE25node_malloc_and_set_valueERKS3_
  9679: 00000000000d3238    68 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP9__toku_dbS2_Lb0EE9node_freeEj
  9697: 00000000001a19e2    16 FUNC    GLOBAL DEFAULT   11
_Z26toku_scoped_malloc_destroyv
  9738: 000000000048ea30     8 OBJECT  GLOBAL DEFAULT   26 __malloc_hook
  9772: 0000000000497688     8 OBJECT  GLOBAL DEFAULT   27 malloc_conf
  9784: 0000000000104210   244 FUNC    GLOBAL DEFAULT   11
_ZN11block_table21free_unused_blocknumsE10blocknum_s
  9834: 0000000000198028   158 FUNC    GLOBAL DEFAULT   11
_ZN7bn_data29mempool_malloc_and_update_dmtEmPPv
  9855: 00000000000c5f89    26 FUNC    GLOBAL DEFAULT   11
db_env_set_func_malloc
  9882: 000000000009aaf6    14 FUNC    WEAK   DEFAULT   11
_ZN7handler28free_foreign_key_create_infoEPc
  9884: 0000000000129a76    26 FUNC    WEAK   DEFAULT   11
_ZN4toku21scoped_malloc_alignedD1Ev
  9918: 00000000001bae6c    42 FUNC    GLOBAL DEFAULT   11
_Z11pqueue_freeP11ft_pqueue_t
  9979: 00000000001d4bf9    26 FUNC    GLOBAL DEFAULT   11
_Z23toku_malloc_usable_sizePv
 10090: 00000000001d67fb   133 FUNC    GLOBAL DEFAULT   11
_Z21os_malloc_usable_sizePKv
 10137: 000000000012af86   128 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIiiLb1EE11node_mallocEv
 10152: 00000000001d3f36   453 FUNC    GLOBAL DEFAULT   11 _Z9toku_freePv
 10167: 0000000000132dc8    68 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtI20referenced_xid_tuplePS1_Lb0EE9node_freeEj
 10168: 000000000019d88e    37 FUNC    GLOBAL DEFAULT   11
_Z30toku_mempool_get_next_free_ptrPK7mempool
 10193: 0000000000180c22    79 FUNC    GLOBAL DEFAULT   11
_Z16toku_ftnode_freePP6ftnode
 10208: 00000000001a1890    84 FUNC    GLOBAL DEFAULT   11
_ZN4toku13scoped_mallocD2Ev
 10305: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND my_free
 10314: 0000000000133dfc   138 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtI20referenced_xid_tuplePS1_Lb0EE11node_mallocEv
 10323: 00000000001b4f34   104 FUNC    GLOBAL DEFAULT   11
_ZN15block_allocator11_trace_freeEm
 10340: 0000000000159c50   138 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP14file_map_tupleS2_Lb0EE11node_mallocEv
 10429: 0000000000139b3d    81 FUNC    GLOBAL DEFAULT   11
_Z25toku_logger_free_logfilesPPci
 10532: 00000000001951f2   138 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP2ftS2_Lb0EE11node_mallocEv
 10685: 00000000001d66b6    26 FUNC    GLOBAL DEFAULT   11 _Z9os_mallocm
 10787: 0000000000498340     8 OBJECT  GLOBAL DEFAULT   27 malloc_message
 10822: 00000000001d4d11    21 FUNC    GLOBAL DEFAULT   11
_Z18toku_set_func_freePFvPvE
 10837: 000000000010417a    75 FUNC    GLOBAL DEFAULT   11
_ZN11block_table13free_blocknumEP10blocknum_sP2ftb
 10872: 00000000000c5fbd    26 FUNC    GLOBAL DEFAULT   11
db_env_set_func_free
 10893: 0000000000115284    68 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP9cachefileS2_Lb0EE9node_freeEj
 10894: 00000000001d2cb3   978 FUNC    GLOBAL DEFAULT   11 _Z11toku_mallocm
 10952: 0000000000099dcc    82 FUNC    WEAK   DEFAULT   11 _ZN6String4freeEv
 10954: 00000000000d545e   142 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtI17txn_lt_key_rangesS1_Lb0EE11node_mallocEv
 11020: 0000000000103384    88 FUNC    GLOBAL DEFAULT   11
_ZN11block_table31_verify_valid_freeable_blocknumEPNS_11translationE10blocknum_s
 11025: 00000000001a18e4   254 FUNC    GLOBAL DEFAULT   11
_Z23toku_scoped_malloc_initv
 11093: 00000000001a17fa   150 FUNC    GLOBAL DEFAULT   11
_ZN4toku13scoped_mallocC2Em
 11169: 00000000001154a6   138 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP9cachefileS2_Lb0EE11node_mallocEv
 11220: 00000000000fcac9    38 FUNC    GLOBAL DEFAULT   11
_Z12toku_ft_freeP2ft
 11252: 00000000001d4c9d    21 FUNC    GLOBAL DEFAULT   11
_Z26toku_set_func_xmalloc_onlyPFPvmE
 11260: 00000000001a17fa   150 FUNC    GLOBAL DEFAULT   11
_ZN4toku13scoped_mallocC1Em
 11277: 00000000001041c6    73 FUNC    GLOBAL DEFAULT   11
_ZN11block_table24verify_no_free_blocknumsEv
 11284: 00000000001d66d0    72 FUNC    GLOBAL DEFAULT   11
_Z17os_malloc_alignedmm
 11296: 000000000016f159   590 FUNC    GLOBAL DEFAULT   11
_Z33toku_log_free_log_entry_resourcesP9log_entry
 11315: 000000000013332c   138 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP7tokutxnS2_Lb0EE11node_mallocEv
 11357: 0000000000129932   306 FUNC    WEAK   DEFAULT   11
_ZN4toku21scoped_malloc_alignedC2Emm
 11365: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND my_malloc
 11469: 00000000001123c6   386 FUNC    GLOBAL DEFAULT   11
_ZN14cachefile_list15free_stale_dataEP7evictor
 11474: 0000000000189c88   128 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIiiLb0EE11node_mallocEv
 11486: 000000000019d8c5    32 FUNC    GLOBAL DEFAULT   11
_Z26toku_mempool_get_free_sizePK7mempool
 11515: 000000000048ea28     8 OBJECT  GLOBAL DEFAULT   26 __free_hook
 11590: 00000000000a4430  1410 FUNC    GLOBAL DEFAULT   11 free
 11615: 00000000000d2eb6   138 FUNC    WEAK   DEFAULT   11
_ZN4toku3omtIP9__toku_dbS2_Lb0EE11node_mallocEv
 11623: 000000000009e5b0  5253 FUNC    GLOBAL DEFAULT   11 mallocx
 11627: 00000000001a19f2   266 FUNC    GLOBAL DEFAULT   11
_Z30toku_scoped_malloc_destroy_setv
 11667: 0000000000129932   306 FUNC    WEAK   DEFAULT   11
_ZN4toku21scoped_malloc_alignedC1Emm
 11674: 0000000000129a64    18 FUNC    WEAK   DEFAULT   11
_ZNK4toku21scoped_malloc_aligned3getEv
 11697: 000000000019dac0   238 FUNC    GLOBAL DEFAULT   11
_Z18toku_mempool_mfreeP7mempoolPvm
 11780: 00000000001d3085  1005 FUNC    GLOBAL DEFAULT   11
_Z19toku_malloc_alignedmm
 11798: 000000000010330a   121 FUNC    GLOBAL DEFAULT   11
_ZN11block_table27_is_valid_freeable_blocknumEPNS_11translationE10blocknum_s
 11857: 00000000001b4414   274 FUNC    GLOBAL DEFAULT   11
_ZN15block_allocator10free_blockEm
 11923: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND my_hash_free

On Tue, Sep 1, 2015 at 9:40 AM, Roel Van de Paar <roel.vandepaar at percona.com
> wrote:

> Hi Florian, Others,
>
> Any ideas/suggestions? Thank you
>
> On Tue, Aug 25, 2015 at 10:24 AM, Roel Van de Paar <
> roel.vandepaar at percona.com> wrote:
>
>> Hi Florian,
>>
>> Thank you for the reply. My reply inline.
>>
>> On Tue, Aug 25, 2015 at 5:13 AM, Florian Weimer <fw at deneb.enyo.de> wrote:
>>
>>> * Roel Van de Paar:
>>>
>>> > What happens if jemalloc is LD_PRELOAD'ed for an executable where such
>>> > executable uses a .so library, which in turn is statically linked with
>>> > jemalloc?
>>>
>>> That depends on what kind of symbols the libary exports.  What does
>>> ?eu-readelf -s? or ?readelf -W -s? show?  If jemalloc symbols are
>>> listed there, quite bad things can happen.
>>
>>
>> [roel at localhost
>> Percona-Server-5.6.25-rel73.2-f9f2b02.Linux.x86_64-debug]$ readelf -W -s
>> ./lib/mysql/plugin/ha_tokudb.so | grep jemalloc
>>    219: 000000000048ed90     4 OBJECT  LOCAL  DEFAULT   27
>> _ZL21tokudb_check_jemalloc
>>    220: 000000000048d4e0    64 OBJECT  LOCAL  DEFAULT   26
>> _ZL27mysql_sysvar_check_jemalloc
>>    833: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS jemalloc.pic.o
>>    840: 000000000009d710    94 FUNC    LOCAL  DEFAULT   11
>> jemalloc_constructor
>>   8370: 000000000009d0d0    90 FUNC    LOCAL  DEFAULT   11
>> je_jemalloc_prefork
>>   8494: 000000000009d010    89 FUNC    LOCAL  DEFAULT   11
>> je_jemalloc_postfork_child
>>   8659: 000000000009d070    89 FUNC    LOCAL  DEFAULT   11
>> je_jemalloc_postfork_parent
>>
>> Are these jemalloc symbols?
>>
>> Also, anyone any idea on the other questions too?
>>
>> --
>>
>> Kind Regards,
>> God Bless,
>> --
>> Roel Van de Paar, CMDBA/CMDEV Senior QA Lead, Percona
>> Tel: +61 2 8004 1288 (UTC+10)
>> Mob: +61 427 141 635 (UTC+10)
>> Skype: percona.rvandepaar
>> http://www.percona.com/services.html
>>
>> Looking for Replication with Data Consistency?
>> Try Percona XtraDB Cluster
>> <http://www.percona.com/software/percona-xtradb-cluster>!
>>
>
>
>
> --
>
> Kind Regards,
> God Bless,
> --
> Roel Van de Paar, CMDBA/CMDEV Senior QA Lead, Percona
> Tel: +61 2 8004 1288 (UTC+10)
> Mob: +61 427 141 635 (UTC+10)
> Skype: percona.rvandepaar
> http://www.percona.com/services.html
>
> Looking for Replication with Data Consistency?
> Try Percona XtraDB Cluster
> <http://www.percona.com/software/percona-xtradb-cluster>!
>



-- 

Kind Regards,
God Bless,
-- 
Roel Van de Paar, CMDBA/CMDEV Senior QA Lead, Percona
Tel: +61 2 8004 1288 (UTC+10)
Mob: +61 427 141 635 (UTC+10)
Skype: percona.rvandepaar
http://www.percona.com/services.html

Looking for Replication with Data Consistency?
Try Percona XtraDB Cluster
<http://www.percona.com/software/percona-xtradb-cluster>!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://www.canonware.com/pipermail/jemalloc-discuss/attachments/20150901/734d5fc8/attachment-0001.html>

